<!DOCTYPE HTML>
<html><head><title>You Could Have Invented Matrices! · in Code</title><meta name="description" content="Weblog of Justin Le, covering his various adventures in programming and explorations in the vast worlds of computation physics, and knowledge."><meta http-equiv="Content-Type" content="text/html;charset=utf-8"><meta name="viewport" content="width=device-width,initial-scale=1.0"><meta name="flattr:id" content="3p9jqr"><meta property="og:site_name" content="in Code"><meta property="og:description" content="You could have invented matrices! Let’s talk about vectors. A vector (denoted as \mathbf{x}, a lower-case bold italicized letter) is an element in a vector space, which means that it can be “scaled”, like c \mathbf{x} (the c is called a “scalar” — creative name, right?) and added, like \mathbf{x} + \mathbf{y}. In order for vector spaces and their operations to be valid, they just have to obey some common-sense rules (like associativity, commutativity, distributivity, etc.) that allow us to make meaningful conclusions."><meta property="og:type" content="article"><meta property="og:title" content="You Could Have Invented Matrices!"><meta property="og:image" content="https://blog.jle.im/img/site_logo.jpg"><meta property="og:locale" content="en_US"><meta property="og:url" content="https://blog.jle.im/entry/you-could-have-invented-matrices.html"><meta name="twitter:card" content="summary"><meta name="twitter:creator:id" content="mstk"><link rel="author" href="https://plus.google.com/107705320197444500140"><link rel="alternate" type="application/rss+xml" title="in Code (RSS Feed)" href="http://feeds.feedburner.com/incodeblog"><link rel="canonical" href="https://blog.jle.im/entry/you-could-have-invented-matrices.html"><link href="https://blog.jle.im/favicon.ico" rel="shortcut icon"><link href="https://blog.jle.im/css/toast.css" rel="stylesheet" type="text/css"><link href="https://blog.jle.im/css/font.css" rel="stylesheet" type="text/css"><link href="https://blog.jle.im/css/main.css" rel="stylesheet" type="text/css"><link href="https://blog.jle.im/css/page/entry.css" rel="stylesheet" type="text/css"><link href="https://blog.jle.im/css/pygments.css" rel="stylesheet" type="text/css"><script type="text/javascript">var page_data = {};
var disqus_shortname='incode';
</script><script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');
ga('create', 'UA-443711-8', 'jle.im');
ga('send', 'pageview');
</script><script type="text/javascript" src="//ajax.googleapis.com/ajax/libs/jquery/1.10.2/jquery.min.js"></script><script type="text/javascript" src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5234d67a6b68dcd4"></script><script type="text/javascript" src="https://blog.jle.im/js/page/entry_toc.js"></script><script type="text/javascript" src="https://blog.jle.im/js/disqus_count.js"></script><script type="text/javascript" src="https://blog.jle.im/js/social.js"></script><script type="text/javascript" src="https://blog.jle.im/js/jquery/jquery.toc.js"></script><script type="text/javascript" src="https://blog.jle.im/purescript/entry.js"></script></head><body><div id="fb-root"><script>(function(d, s, id) {
 var js, fjs = d.getElementsByTagName(s)[0];
 if (d.getElementById(id)) return;
 js = d.createElement(s); js.id = id;
 js.src = "//connect.facebook.net/en_US/all.js#xfbml=1&appId=641852699171929";
 fjs.parentNode.insertBefore(js, fjs);
}(document, 'script', 'facebook-jssdk'));
</script></div><div id="header-container"><div id="navbar-container" class="tile"><nav id="navbar-content"><div class="nav-info"><h1 class="site-title"><a href="https://blog.jle.im/" class="nav-title">in Code</a></h1><span class="nav-author">Justin Le</span></div><ul class="nav-links"><li><a href="https://blog.jle.im/">home</a></li><li><a href="https://blog.jle.im/entries.html">archives</a></li><div class="clear"></div></ul></nav></div><div id="header-content"></div></div><div id="body-container" class="container"><div id="main-container" class="grid"><div class="entry-section unit span-grid" role="main"><article class="tile article"><header><h1 id="title">You Could Have Invented Matrices!</h1><p class="entry-info">by <a class="author" href="https://blog.jle.im/">Justin Le</a><span class="info-separator"> &diams; </span><time datetime="2018-03-15T10:15:54Z" pubdate="" class="pubdate">Thursday March 15, 2018</time></p><p><span class="source-info"><a class="source-link" href="https://github.com/mstksg/inCode/tree/master/copy/entries/invent-matrices.md">Source</a><span class="info-separator"> &diams; </span><a class="source-link" href="https://github.com/mstksg/inCode/tree/gh-pages/entry/you-could-have-invented-matrices.md">Markdown</a><span class="info-separator"> &diams; </span><a class="source-link" href="https://blog.jle.im/entry/you-could-have-invented-matrices.tex">LaTeX</a><span class="info-separator"> &diams; </span></span>Posted in <a href="https://blog.jle.im/entries/category/@math.html" class="tag-a-category" title="@MATH">Math</a><span class="info-separator"> &diams; </span><a class="comment-link" href="#disqus_thread">Comments</a></p></header><hr><aside class="contents-container"><h5 id="contents-header">Contents</h5><div id="toc"></div></aside><div class="main-content copy-content"><p>You could have invented matrices!</p>
<p>Let’s talk about vectors. A <strong>vector</strong> (denoted as <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D" alt="\mathbf{x}" title="\mathbf{x}" />, a lower-case bold italicized letter) is an element in a <strong>vector space</strong>, which means that it can be “scaled”, like <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?c%20%5Cmathbf%7Bx%7D" alt="c \mathbf{x}" title="c \mathbf{x}" /> (the <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?c" alt="c" title="c" /> is called a “scalar” — creative name, right?) and added, like <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D%20%2B%20%5Cmathbf%7By%7D" alt="\mathbf{x} + \mathbf{y}" title="\mathbf{x} + \mathbf{y}" />.</p>
<p>In order for vector spaces and their operations to be valid, they just have to obey some <a href="https://en.wikipedia.org/wiki/Vector_space#Definition">common-sense rules</a> (like associativity, commutativity, distributivity, etc.) that allow us to make meaningful conclusions.</p>
<h2 id="dimensionality">Dimensionality</h2>
<p>One neat thing about vector spaces is that, in <em>some</em> of them, you have the ability to “decompose” any vector in it as a weighted sum of some set of <strong>basis vectors</strong>. If this is the case for your vector space, then the size of smallest possible set of basis vectors is known as the <strong>dimension</strong> of that vector space.</p>
<p>For example, for a 3-dimensional vector space <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?V" alt="V" title="V" />, any vector <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D" alt="\mathbf{x}" title="\mathbf{x}" /> can be described as a weighted sum of three basis vectors. If we call them <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bv%7D_1" alt="\mathbf{v}_1" title="\mathbf{v}_1" />, <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bv%7D_2" alt="\mathbf{v}_2" title="\mathbf{v}_2" />, <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bv%7D_3" alt="\mathbf{v}_3" title="\mathbf{v}_3" />, then:</p>
<p><br /><img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?%0A%5Cmathbf%7Bx%7D%20%3D%20a%20%5Cmathbf%7Bv%7D_1%20%2B%20b%20%5Cmathbf%7Bv%7D_2%20%2B%20c%20%5Cmathbf%7Bv%7D_3%0A" alt="
\mathbf{x} = a \mathbf{v}_1 + b \mathbf{v}_2 + c \mathbf{v}_3
" title="
\mathbf{x} = a \mathbf{v}_1 + b \mathbf{v}_2 + c \mathbf{v}_3
" /><br /></p>
<p>Where <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?a" alt="a" title="a" />, <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?b" alt="b" title="b" />, and <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?c" alt="c" title="c" /> are scalars of <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?V" alt="V" title="V" />.</p>
<p>Dimensionality is really a statement about being able to <em>decompose</em> any vector in that vector space into a combination of a set of basis vectors. For a 3-dimensional vector space, you can make a bases that can reproduce <em>any</em> vector in your space…but that’s only possible with at least three vectors. a 4-dimensional vector space, you’d need at least four vectors.</p>
<p>For example, in physics, we often treat reality as taking place in a three-dimensional vector space. The basis vectors are often called <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?%5Chat%7B%5Cmathbf%7Bi%7D%7D" alt="\hat{\mathbf{i}}" title="\hat{\mathbf{i}}" />, <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?%5Chat%7B%5Cmathbf%7Bj%7D%7D" alt="\hat{\mathbf{j}}" title="\hat{\mathbf{j}}" />, and <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?%5Chat%7B%5Cmathbf%7Bk%7D%7D" alt="\hat{\mathbf{k}}" title="\hat{\mathbf{k}}" />, and so we say that we can describe our 3D physics vectors as <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Br%7D%20%3D%20r_x%20%5Chat%7B%5Cmathbf%7Bi%7D%7D%20%2B%20r_y%20%5Chat%7B%5Cmathbf%7Bj%7D%7D%20%2B%20r_x%20%5Chat%7B%5Cmathbf%7Bk%7D%7D" alt="\mathbf{r} = r_x \hat{\mathbf{i}} + r_y \hat{\mathbf{j}} + r_x \hat{\mathbf{k}}" title="\mathbf{r} = r_x \hat{\mathbf{i}} + r_y \hat{\mathbf{j}} + r_x \hat{\mathbf{k}}" />.</p>
<h3 id="encoding">Encoding</h3>
<p>One neat thing that physicists take advantage of all the time is that if we <em>agree</em> on a set of basis vectors and a specific ordering, we can actually <em>encode</em> any vector <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D" alt="\mathbf{x}" title="\mathbf{x}" /> in terms of those basis vectors.</p>
<p>In physics, for instance, we can say “Let’s encode vectors in terms of sums of scalings of <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?%5Chat%7B%5Cmathbf%7Bi%7D%7D" alt="\hat{\mathbf{i}}" title="\hat{\mathbf{i}}" />, <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?%5Chat%7B%5Cmathbf%7Bj%7D%7D" alt="\hat{\mathbf{j}}" title="\hat{\mathbf{j}}" />, and <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?%5Chat%7B%5Cmathbf%7Bk%7D%7D" alt="\hat{\mathbf{k}}" title="\hat{\mathbf{k}}" />, in that order.” Then, we can <em>write</em> <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Br%7D" alt="\mathbf{r}" title="\mathbf{r}" /> as <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?%5Clangle%20r_x%2C%20r_y%2C%20r_z%20%5Crangle" alt="\langle r_x, r_y, r_z \rangle" title="\langle r_x, r_y, r_z \rangle" />, and understand that we really mean <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Br%7D%20%3D%20r_x%20%5Chat%7B%5Cmathbf%7Bi%7D%7D%20%2B%20r_y%20%5Chat%7B%5Cmathbf%7Bj%7D%7D%20%2B%20r_x%20%5Chat%7B%5Cmathbf%7Bk%7D%7D" alt="\mathbf{r} = r_x \hat{\mathbf{i}} + r_y \hat{\mathbf{j}} + r_x \hat{\mathbf{k}}" title="\mathbf{r} = r_x \hat{\mathbf{i}} + r_y \hat{\mathbf{j}} + r_x \hat{\mathbf{k}}" />.</p>
<p>It should be made clear that <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?%5Clangle%20x_1%2C%20x_2%2C%20x_3%20%5Crangle" alt="\langle x_1, x_2, x_3 \rangle" title="\langle x_1, x_2, x_3 \rangle" /> is <strong>not</strong> the same thing as the <em>vector</em> <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D" alt="\mathbf{x}" title="\mathbf{x}" />. It is <em>an encoding</em> of that vector, which only makes sense once we choose to <em>agree</em> on a specific set of basis. If we chose a different basis, we’d have a different encoding.</p>
<p>In the general case, for an N-dimensional vector space, this means that, with a minimum of N items, we can represent any vector in that space. And, if we agree on those N items, we can devise an encoding, such that:</p>
<p><br /><img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?%0A%5Clangle%20x_1%2C%20x_2%20%5Cdots%20x_N%20%5Crangle%0A" alt="
\langle x_1, x_2 \dots x_N \rangle
" title="
\langle x_1, x_2 \dots x_N \rangle
" /><br /></p>
<p>will <em>encode</em> the vector:</p>
<p><br /><img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?%0Ax_1%20%5Cmathbf%7Bv%7D_1%20%2B%20x_2%20%5Cmathbf%7Bv%7D_2%20%2B%20%5Cldots%20%2B%20x_N%20%5Cmathbf%7Bv%7D_N%0A" alt="
x_1 \mathbf{v}_1 + x_2 \mathbf{v}_2 + \ldots + x_N \mathbf{v}_N
" title="
x_1 \mathbf{v}_1 + x_2 \mathbf{v}_2 + \ldots + x_N \mathbf{v}_N
" /><br /></p>
<p>Note that what this encoding represents is <em>completely dependent</em> on what <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bv%7D_1%2C%20%5Cmathbf%7Bv%7D_2%20%5Cldots%20%5Cmathbf%7Bv%7D_N" alt="\mathbf{v}_1, \mathbf{v}_2 \ldots \mathbf{v}_N" title="\mathbf{v}_1, \mathbf{v}_2 \ldots \mathbf{v}_N" /> we pick, and in what order. The basis vectors we pick are arbitrary, and determine what our encoding looks like.</p>
<p>To highlight this, note that the same vector <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D" alt="\mathbf{x}" title="\mathbf{x}" /> has many different potential encodings — all you have to do is pick a different set of basis vectors, or even just re-arrange or re-scale the ones you already have. However, all of those encodings correspond go the same vector <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bv%7D" alt="\mathbf{v}" title="\mathbf{v}" />.</p>
<p>One interesting consequence of this is that any N-dimensional vector space whose scalars are in <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?%5Cmathbb%7BR%7D" alt="\mathbb{R}" title="\mathbb{R}" /> is actually isomorphic to <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?%5Cmathbb%7BR%7D%5EN" alt="\mathbb{R}^N" title="\mathbb{R}^N" /> (the vector space of N-tuples of real numbers). This means that we can basically treat any N-dimensional vector space with <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?%5Cmathbb%7BR%7D" alt="\mathbb{R}" title="\mathbb{R}" /> scalars as if it was <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?%5Cmathbb%7BR%7D%5EN" alt="\mathbb{R}^N" title="\mathbb{R}^N" />, <em>once we decide</em> on the basis vectors. Because of this, we often call <em>all</em> N-dimensional vector spaces (whose scalars are in <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?%5Cmathbb%7BR%7D" alt="\mathbb{R}" title="\mathbb{R}" />) <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?%5Cmathbb%7BR%7D%5EN" alt="\mathbb{R}^N" title="\mathbb{R}^N" />. You will often hear physicists saying that the three-dimensional vector spaces they use are <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?%5Cmathbb%7BR%7D%5E3" alt="\mathbb{R}^3" title="\mathbb{R}^3" />. However, what they really mean is that their vector spaces is <em>isomorphic</em> to <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?%5Cmathbb%7BR%7D%5E3" alt="\mathbb{R}^3" title="\mathbb{R}^3" />.</p>
<h2 id="linear-transformations">Linear Transformations</h2>
<p>Now, one of the most interesting things in mathematics is the idea of the <strong>linear transformation</strong>. Linear transformations are useful to study because:</p>
<ol type="1">
<li>They are ubiquitous. They come up everywhere in engineering, physics, mathematics, data science, economics, and pretty much any mathematical theory. And there are even more situations which can be <em>approximated</em> by linear transformations.</li>
<li>They are mathematically very nice to work with and study, in practice.</li>
</ol>
<p>A linear transformation, <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?f%28%5Cmathbf%7Bx%7D%29" alt="f(\mathbf{x})" title="f(\mathbf{x})" />, is a function that “respects” addition and scaling:</p>
<p><br /><img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Baligned%7D%0Af%28c%5Cmathbf%7Bx%7D%29%20%26%20%3D%20c%20f%28%5Cmathbf%7Bx%7D%29%20%5C%5C%0Af%28%5Cmathbf%7Bx%7D%20%2B%20%5Cmathbf%7By%7D%29%20%26%20%3D%20f%28%5Cmathbf%7Bx%7D%29%20%2B%20f%28%5Cmathbf%7By%7D%29%0A%5Cend%7Baligned%7D%0A" alt="
\begin{aligned}
f(c\mathbf{x}) &amp; = c f(\mathbf{x}) \\
f(\mathbf{x} + \mathbf{y}) &amp; = f(\mathbf{x}) + f(\mathbf{y})
\end{aligned}
" title="
\begin{aligned}
f(c\mathbf{x}) &amp; = c f(\mathbf{x}) \\
f(\mathbf{x} + \mathbf{y}) &amp; = f(\mathbf{x}) + f(\mathbf{y})
\end{aligned}
" /><br /></p>
<p>This means that if you scale the input, the output is scaled by the same amount. And also, if you transform the sum of two things, it’s the same as the sum of the transformed things (it “distributes”).</p>
<p>Note that I snuck in vector notation, because the concept of vectors are <em>perfectly suited</em> for studying linear transformations. That’s because talking about linear transformations requires talking about scaling and adding, and…hey, that’s just exactly what vectors have!</p>
<p>From now on, we’ll talk about linear transformations specifically on <em>N-dimensional vector spaces</em> (vector spaces that have dimensions and bases we can use).</p>
<h3 id="studying-linear-transformations">Studying linear transformations</h3>
<p>From first glance, a linear transformation’s description doesn’t look too useful or analyzable. All you have is <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?f%28%5Cmathbf%7Bx%7D%29" alt="f(\mathbf{x})" title="f(\mathbf{x})" />. It could be anything! Right? Just a black box function?</p>
<p>But, actually, we can exploit its linearity and the fact that we’re in a vector space with a basis to analyze the heck out of any linear transformation, and see that all of them actually have to follow some specific pattern.</p>
<p>Let’s say that <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?f%28%5Cmathbf%7Bx%7D%29" alt="f(\mathbf{x})" title="f(\mathbf{x})" /> is a linear transformation from N-dimensional vector space <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?V" alt="V" title="V" /> to M-dimensional vector space <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?U" alt="U" title="U" />. That is, <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?f%20%3A%20V%20%5Crightarrow%20U" alt="f : V \rightarrow U" title="f : V \rightarrow U" />.</p>
<p>Because we know that, once we pick a set of basis vectors <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bv%7D_i" alt="\mathbf{v}_i" title="\mathbf{v}_i" />, any vector <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D" alt="\mathbf{x}" title="\mathbf{x}" /> in <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?V" alt="V" title="V" /> can be decomposed as <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?x_1%20%5Cmathbf%7Bv%7D_1%20%2B%20x_2%20%5Cmathbf%7Bv%7D_2%20%2B%20%5Cldots%20x_n%20%5Cmathbf%7Bv%7D_N" alt="x_1 \mathbf{v}_1 + x_2 \mathbf{v}_2 + \ldots x_n \mathbf{v}_N" title="x_1 \mathbf{v}_1 + x_2 \mathbf{v}_2 + \ldots x_n \mathbf{v}_N" />, we really can just look at how a transformation <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?f" alt="f" title="f" /> acts on this decomposition. For example, if <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?V" alt="V" title="V" /> is three-dimensional:</p>
<p><br /><img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?%0Af%28%5Cmathbf%7Bx%7D%29%20%3D%20f%28x_1%20%5Cmathbf%7Bv%7D_1%20%2B%20x_2%20%5Cmathbf%7Bv%7D_2%20%2B%20x_3%20%5Cmathbf%7Bv%7D_3%29%0A" alt="
f(\mathbf{x}) = f(x_1 \mathbf{v}_1 + x_2 \mathbf{v}_2 + x_3 \mathbf{v}_3)
" title="
f(\mathbf{x}) = f(x_1 \mathbf{v}_1 + x_2 \mathbf{v}_2 + x_3 \mathbf{v}_3)
" /><br /></p>
<p>Hm. Doesn’t seem very insightful, does it?</p>
<h3 id="a-simple-definition">A simple definition</h3>
<p>But! We can exploit the linearity of <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?f" alt="f" title="f" /> (that it distributes and scales) to rewrite that as:</p>
<p><br /><img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?%0Af%28%5Cmathbf%7Bx%7D%29%20%3D%20x_1%20f%28%5Cmathbf%7Bv%7D_1%29%20%2B%20x_2%20f%28%5Cmathbf%7Bv%7D_2%29%20%2B%20x_3%20f%28%5Cmathbf%7Bv%7D_3%29%0A" alt="
f(\mathbf{x}) = x_1 f(\mathbf{v}_1) + x_2 f(\mathbf{v}_2) + x_3 f(\mathbf{v}_3)
" title="
f(\mathbf{x}) = x_1 f(\mathbf{v}_1) + x_2 f(\mathbf{v}_2) + x_3 f(\mathbf{v}_3)
" /><br /></p>
<p>Okay, take a moment to pause and take that all in. This is actually a pretty big deal! This just means that, to study <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?f" alt="f" title="f" />, <strong>all you need to study</strong> is how <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?f" alt="f" title="f" /> acts on our <em>basis vectors</em>. If you know how <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?f" alt="f" title="f" /> acts on our basis vectors of our vector space, that’s really “all there is” about <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?f" alt="f" title="f" />! Not such a black box anymore!</p>
<p>That is, if I were to ask you, “Hey, what is <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?f" alt="f" title="f" /> like?”, <em>all you’d have to tell me</em> is the result of <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?f%28%5Cmathbf%7Bv%7D_1%29" alt="f(\mathbf{v}_1)" title="f(\mathbf{v}_1)" />, <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?f%28%5Cmathbf%7Bv%7D_2%29" alt="f(\mathbf{v}_2)" title="f(\mathbf{v}_2)" />, and <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?f%28%5Cmathbf%7Bv%7D_3%29" alt="f(\mathbf{v}_3)" title="f(\mathbf{v}_3)" />. Just give me those three <em>vectors</em>, and we <em>uniquely determine <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?f" alt="f" title="f" /></em>.</p>
<p>To put in another way, <em>any linear transformation</em> from a three-dimensional vector space is uniquely characterized and determined by <em>three vectors</em>: <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?f%28%5Cmathbf%7Bv%7D_1%29" alt="f(\mathbf{v}_1)" title="f(\mathbf{v}_1)" />, <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?f%28%5Cmathbf%7Bv%7D_2%29" alt="f(\mathbf{v}_2)" title="f(\mathbf{v}_2)" />, and <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?f%28%5Cmathbf%7Bv%7D_3%29" alt="f(\mathbf{v}_3)" title="f(\mathbf{v}_3)" />. Those three vectors <em>completely define</em> <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?f" alt="f" title="f" />.</p>
<p>In general, we see that <em>any linear transformation</em> from an N-dimensional vector space can be <em>completely defined</em> by N vectors: the N results of that transformation on each of N basis vectors we choose.</p>
<h3 id="enter-the-matrix">Enter the Matrix</h3>
<p>Okay, so how do we “give”/define/state those N vectors?</p>
<p>Well, recall that the result of <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?f%28%5Cmathbf%7Bx%7D%29" alt="f(\mathbf{x})" title="f(\mathbf{x})" /> and <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?f%28%5Cmathbf%7Bv%7D_1%29" alt="f(\mathbf{v}_1)" title="f(\mathbf{v}_1)" />, etc. are <em>themselves</em> vectors, in M-dimensional vector space <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?U" alt="U" title="U" />. Let’s say that <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?U" alt="U" title="U" /> is 2-dimensional, for now.</p>
<p>This means that any vector <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?%5Cmathbf%7By%7D" alt="\mathbf{y}" title="\mathbf{y}" /> in <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?U" alt="U" title="U" /> can be represented as <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?y_1%20%5Cmathbf%7Bu%7D_1%20%2B%20y_2%20%5Cmathbf%7Bu%7D_2" alt="y_1 \mathbf{u}_1 + y_2 \mathbf{u}_2" title="y_1 \mathbf{u}_1 + y_2 \mathbf{u}_2" />, where <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bu%7D_1" alt="\mathbf{u}_1" title="\mathbf{u}_1" /> and <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bu%7D_2" alt="\mathbf{u}_2" title="\mathbf{u}_2" /> is an arbitrary choice of basis vectors.</p>
<p>This means that <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?f%28%5Cmathbf%7Bv%7D_1%29" alt="f(\mathbf{v}_1)" title="f(\mathbf{v}_1)" /> etc. can also all be represented in terms of these basis vectors. So, laying it all out:</p>
<p><br /><img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Baligned%7D%0Af%28%5Cmathbf%7Bv%7D_1%29%20%26%20%3D%20a_%7B11%7D%20%5Cmathbf%7Bu%7D_1%20%2B%20a_%7B21%7D%20%5Cmathbf%7Bu%7D_2%20%5C%5C%0Af%28%5Cmathbf%7Bv%7D_2%29%20%26%20%3D%20a_%7B12%7D%20%5Cmathbf%7Bu%7D_1%20%2B%20a_%7B22%7D%20%5Cmathbf%7Bu%7D_2%20%5C%5C%0Af%28%5Cmathbf%7Bv%7D_3%29%20%26%20%3D%20a_%7B13%7D%20%5Cmathbf%7Bu%7D_1%20%2B%20a_%7B23%7D%20%5Cmathbf%7Bu%7D_2%0A%5Cend%7Baligned%7D%0A" alt="
\begin{aligned}
f(\mathbf{v}_1) &amp; = a_{11} \mathbf{u}_1 + a_{21} \mathbf{u}_2 \\
f(\mathbf{v}_2) &amp; = a_{12} \mathbf{u}_1 + a_{22} \mathbf{u}_2 \\
f(\mathbf{v}_3) &amp; = a_{13} \mathbf{u}_1 + a_{23} \mathbf{u}_2
\end{aligned}
" title="
\begin{aligned}
f(\mathbf{v}_1) &amp; = a_{11} \mathbf{u}_1 + a_{21} \mathbf{u}_2 \\
f(\mathbf{v}_2) &amp; = a_{12} \mathbf{u}_1 + a_{22} \mathbf{u}_2 \\
f(\mathbf{v}_3) &amp; = a_{13} \mathbf{u}_1 + a_{23} \mathbf{u}_2
\end{aligned}
" /><br /></p>
<p>Or, to use our bracket notation from before:</p>
<p><br /><img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Baligned%7D%0Af%28%5Cmathbf%7Bv%7D_1%29%20%26%20%3D%20%5Clangle%20a_%7B11%7D%2C%20a_%7B21%7D%20%5Crangle%20%5C%5C%0Af%28%5Cmathbf%7Bv%7D_2%29%20%26%20%3D%20%5Clangle%20a_%7B12%7D%2C%20a_%7B22%7D%20%5Crangle%20%5C%5C%0Af%28%5Cmathbf%7Bv%7D_3%29%20%26%20%3D%20%5Clangle%20a_%7B13%7D%2C%20a_%7B23%7D%20%5Crangle%0A%5Cend%7Baligned%7D%0A" alt="
\begin{aligned}
f(\mathbf{v}_1) &amp; = \langle a_{11}, a_{21} \rangle \\
f(\mathbf{v}_2) &amp; = \langle a_{12}, a_{22} \rangle \\
f(\mathbf{v}_3) &amp; = \langle a_{13}, a_{23} \rangle
\end{aligned}
" title="
\begin{aligned}
f(\mathbf{v}_1) &amp; = \langle a_{11}, a_{21} \rangle \\
f(\mathbf{v}_2) &amp; = \langle a_{12}, a_{22} \rangle \\
f(\mathbf{v}_3) &amp; = \langle a_{13}, a_{23} \rangle
\end{aligned}
" /><br /></p>
<p>So, we now see two facts:</p>
<ol type="1">
<li>A linear transformation from an N dimensional vector space to an M dimensional vector space can be <em>defined</em> using N vectors.</li>
<li>Each of those N vectors can, themselves, be defined using M scalars each.</li>
</ol>
<p>Our final conclusion: <em>any</em> linear transformation from an N dimensional vector space to an M dimensional vector space can be completely defined using <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?N%20M" alt="N M" title="N M" /> scalars.</p>
<p>That’s right – <em>all</em> possible linear transformations from a 3-dimensional vector space to a 2-dimensional are parameterized by only <em>six</em> scalars! These six scalars uniquely determine and define our linear transformation, given a set of basis vectors that we agree on. All linear transformations <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?%5Cmathbb%7BR%7D%5E3%20%5Crightarrow%20%5Cmathbb%7BR%7D%5E2" alt="\mathbb{R}^3 \rightarrow \mathbb{R}^2" title="\mathbb{R}^3 \rightarrow \mathbb{R}^2" /> can be defined/encoded/expressed with just six real numbers.</p>
<p>These six numbers are pretty important. Just like how we often talk about 3-dimensional vectors in terms of the encoding of their three coefficients, we often talk about linear transformations from 3-d space to 2-d space in terms of their six defining coefficients.</p>
<p>We group these things up in something called a <em>matrix</em>.</p>
<p>If our linear transformation <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?f" alt="f" title="f" /> from a 3-dimensional vector space to a 2-dimensional vector space is defined by:</p>
<p><br /><img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Baligned%7D%0Af%28%5Cmathbf%7Bv%7D_1%29%20%26%20%3D%20a_%7B11%7D%20%5Cmathbf%7Bu%7D_1%20%2B%20a_%7B21%7D%20%5Cmathbf%7Bu%7D_2%20%5C%5C%0Af%28%5Cmathbf%7Bv%7D_2%29%20%26%20%3D%20a_%7B12%7D%20%5Cmathbf%7Bu%7D_1%20%2B%20a_%7B22%7D%20%5Cmathbf%7Bu%7D_2%20%5C%5C%0Af%28%5Cmathbf%7Bv%7D_3%29%20%26%20%3D%20a_%7B13%7D%20%5Cmathbf%7Bu%7D_1%20%2B%20a_%7B23%7D%20%5Cmathbf%7Bu%7D_2%0A%5Cend%7Baligned%7D%0A" alt="
\begin{aligned}
f(\mathbf{v}_1) &amp; = a_{11} \mathbf{u}_1 + a_{21} \mathbf{u}_2 \\
f(\mathbf{v}_2) &amp; = a_{12} \mathbf{u}_1 + a_{22} \mathbf{u}_2 \\
f(\mathbf{v}_3) &amp; = a_{13} \mathbf{u}_1 + a_{23} \mathbf{u}_2
\end{aligned}
" title="
\begin{aligned}
f(\mathbf{v}_1) &amp; = a_{11} \mathbf{u}_1 + a_{21} \mathbf{u}_2 \\
f(\mathbf{v}_2) &amp; = a_{12} \mathbf{u}_1 + a_{22} \mathbf{u}_2 \\
f(\mathbf{v}_3) &amp; = a_{13} \mathbf{u}_1 + a_{23} \mathbf{u}_2
\end{aligned}
" /><br /></p>
<p>(for arbitrary choice of bases <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bv%7D_i" alt="\mathbf{v}_i" title="\mathbf{v}_i" /> and <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bu%7D_i" alt="\mathbf{u}_i" title="\mathbf{u}_i" />)</p>
<p>We “encode” it as the matrix:</p>
<p><br /><img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?%0Af%0A%5Csim%0A%5Cbegin%7Bbmatrix%7D%0Aa_%7B11%7D%20%26%20a_%7B12%7D%20%26%20a_%7B13%7D%20%5C%5C%0Aa_%7B21%7D%20%26%20a_%7B22%7D%20%26%20a_%7B23%7D%0A%5Cend%7Bbmatrix%7D%0A" alt="
f
\sim
\begin{bmatrix}
a_{11} &amp; a_{12} &amp; a_{13} \\
a_{21} &amp; a_{22} &amp; a_{23}
\end{bmatrix}
" title="
f
\sim
\begin{bmatrix}
a_{11} &amp; a_{12} &amp; a_{13} \\
a_{21} &amp; a_{22} &amp; a_{23}
\end{bmatrix}
" /><br /></p>
<p>And that’s why we use matrices in linear algebra – like how <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?%5Clangle%20x%2C%20y%2C%20z%20%5Crangle" alt="\langle x, y, z \rangle" title="\langle x, y, z \rangle" /> is a convenient way to represent and define a <em>vector</em> (once we agree on a bases), a <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?M%20%5Ctimes%20N" alt="M \times N" title="M \times N" /> matrix is a convenient way to represent and define a <em>linear transformation</em> from an N-dimensional vector space to a M-dimensional vector space (once we agree on the bases in both spaces).</p>
<h3 id="example">Example</h3>
<p>Let’s look at the vector space of polynomials, which includes vectors like <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?5%20p%5E2%20-%203%20p%20%2B%202" alt="5 p^2 - 3 p + 2" title="5 p^2 - 3 p + 2" />, etc.; scaling a polynomial just means scaling the coefficients, and adding together polynomials is just normal polynomial addition.</p>
<p>It’s an infinite-dimensional vector space, and one popular basis for this vector space is the polynomials <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?1%2C%20p%2C%20p%5E2%2C%20p%5E3%2C%20%5Cldots" alt="1, p, p^2, p^3, \ldots" title="1, p, p^2, p^3, \ldots" />, etc.</p>
<p>With this choice of basis, we can encode a polynomial like <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?5%20p%5E2%20-%203%20p%20%2B%202" alt="5 p^2 - 3 p + 2" title="5 p^2 - 3 p + 2" /> with the notation <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?%5Clangle%202%2C%20-3%2C%205%2C%200%2C%200%2C%20%5Cldots%20%5Crangle" alt="\langle 2, -3, 5, 0, 0, \ldots \rangle" title="\langle 2, -3, 5, 0, 0, \ldots \rangle" />.</p>
<p>One popular linear transformation on polynomials is the derivative, <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?%5Cfrac%7Bd%7D%7Bdp%7D" alt="\frac{d}{dp}" title="\frac{d}{dp}" />. It takes <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?5%20p%5E2%20-%203%20p%20%2B%202" alt="5 p^2 - 3 p + 2" title="5 p^2 - 3 p + 2" /> and returns <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?10%20p%20-%203" alt="10 p - 3" title="10 p - 3" />. In the basis we just mentioned, it takes <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?%5Clangle%202%2C%20-3%2C%205%2C%200%2C%20%5Cldots%20%5Crangle" alt="\langle 2, -3, 5, 0, \ldots \rangle" title="\langle 2, -3, 5, 0, \ldots \rangle" /> and returns <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?%5Clangle%20-3%2C%2010%2C%200%2C%200%2C%20%5Cldots%20%5Crangle" alt="\langle -3, 10, 0, 0, \ldots \rangle" title="\langle -3, 10, 0, 0, \ldots \rangle" />.</p>
<p>Now, if you don’t know what a derivative was, or how to compute it – you’re in luck! What we just found out was that if you want to completely understand a linear transformation, you just need to know <em>how it works on the basis</em>! You just need to know what <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?%5Cfrac%7Bd%7D%7Bdp%7D%201%2C%20%5Cfrac%7Bd%7D%7Bdp%7D%20p%2C%20%5Cfrac%7Bd%7D%7Bdp%7D%20p%5E2%2C%20%5Cfrac%7Bd%7D%7Bdp%7D%20p%5E3%2C%20%5Cldots" alt="\frac{d}{dp} 1, \frac{d}{dp} p, \frac{d}{dp} p^2, \frac{d}{dp} p^3, \ldots" title="\frac{d}{dp} 1, \frac{d}{dp} p, \frac{d}{dp} p^2, \frac{d}{dp} p^3, \ldots" /> etc. are, and you basically know everything about what the derivative does.</p>
<p>All I need to do is tell you that <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?%5Cfrac%7Bd%7D%7Bdp%7D%20p%5En%20%3D%20n%20p%5E%7Bn%20-%201%7D" alt="\frac{d}{dp} p^n = n p^{n - 1}" title="\frac{d}{dp} p^n = n p^{n - 1}" /> (what it does to each basis – the trusty <a href="https://en.wikipedia.org/wiki/Power_rule">power rule</a>), and now you know everything you need to know about derivatives on polynomials. You can basically just skip all of calculus!</p>
<p>Let’s look at what this linear transformation does to each basis:</p>
<p><br /><img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Baligned%7D%0A%5Cfrac%7Bd%7D%7Bdp%7D%201%20%20%20%26%20%3D%200%20%20%20%20%20%26%20%3D%200%20%2B%200%20p%20%2B%200%20p%5E2%20%2B%200%20p%5E3%20%2B%20%5Cldots%0A%20%20%20%20%26%20%3D%20%5Clangle%200%2C%200%2C%200%2C%200%20%5Cldots%20%5Crangle%20%20%5C%5C%0A%5Cfrac%7Bd%7D%7Bdp%7D%20p%20%20%20%26%20%3D%201%20%20%20%20%20%26%20%3D%201%20%2B%200%20p%20%2B%200%20p%5E2%20%2B%200%20p%5E3%20%2B%20%5Cldots%0A%20%20%20%20%26%20%3D%20%5Clangle%201%2C%200%2C%200%2C%200%20%5Cldots%20%5Crangle%20%20%5C%5C%0A%5Cfrac%7Bd%7D%7Bdp%7D%20p%5E2%20%26%20%3D%202%20p%20%20%20%26%20%3D%200%20%2B%202%20p%20%2B%200%20p%5E2%20%2B%200%20p%5E3%20%2B%20%5Cldots%0A%20%20%20%20%26%20%3D%20%5Clangle%200%2C%202%2C%200%2C%200%20%5Cldots%20%5Crangle%20%20%5C%5C%0A%5Cfrac%7Bd%7D%7Bdp%7D%20p%5E3%20%26%20%3D%203%20p%5E2%20%26%20%3D%200%20%2B%200%20p%20%2B%203%20p%5E2%20%2B%200%20p%5E3%20%2B%20%5Cldots%0A%20%20%20%20%26%20%3D%20%5Clangle%200%2C%200%2C%203%2C%200%20%5Cldots%20%5Crangle%20%20%5C%5C%0A%5Cfrac%7Bd%7D%7Bdp%7D%20p%5E4%20%26%20%3D%204%20p%5E3%20%26%20%3D%200%20%2B%200%20p%20%2B%200%20p%5E2%20%2B%204%20p%5E3%20%2B%20%5Cldots%0A%20%20%20%20%26%20%3D%20%5Clangle%200%2C%200%2C%200%2C%204%20%5Cldots%20%5Crangle%0A%5Cend%7Baligned%7D%0A" alt="
\begin{aligned}
\frac{d}{dp} 1   &amp; = 0     &amp; = 0 + 0 p + 0 p^2 + 0 p^3 + \ldots
    &amp; = \langle 0, 0, 0, 0 \ldots \rangle  \\
\frac{d}{dp} p   &amp; = 1     &amp; = 1 + 0 p + 0 p^2 + 0 p^3 + \ldots
    &amp; = \langle 1, 0, 0, 0 \ldots \rangle  \\
\frac{d}{dp} p^2 &amp; = 2 p   &amp; = 0 + 2 p + 0 p^2 + 0 p^3 + \ldots
    &amp; = \langle 0, 2, 0, 0 \ldots \rangle  \\
\frac{d}{dp} p^3 &amp; = 3 p^2 &amp; = 0 + 0 p + 3 p^2 + 0 p^3 + \ldots
    &amp; = \langle 0, 0, 3, 0 \ldots \rangle  \\
\frac{d}{dp} p^4 &amp; = 4 p^3 &amp; = 0 + 0 p + 0 p^2 + 4 p^3 + \ldots
    &amp; = \langle 0, 0, 0, 4 \ldots \rangle
\end{aligned}
" title="
\begin{aligned}
\frac{d}{dp} 1   &amp; = 0     &amp; = 0 + 0 p + 0 p^2 + 0 p^3 + \ldots
    &amp; = \langle 0, 0, 0, 0 \ldots \rangle  \\
\frac{d}{dp} p   &amp; = 1     &amp; = 1 + 0 p + 0 p^2 + 0 p^3 + \ldots
    &amp; = \langle 1, 0, 0, 0 \ldots \rangle  \\
\frac{d}{dp} p^2 &amp; = 2 p   &amp; = 0 + 2 p + 0 p^2 + 0 p^3 + \ldots
    &amp; = \langle 0, 2, 0, 0 \ldots \rangle  \\
\frac{d}{dp} p^3 &amp; = 3 p^2 &amp; = 0 + 0 p + 3 p^2 + 0 p^3 + \ldots
    &amp; = \langle 0, 0, 3, 0 \ldots \rangle  \\
\frac{d}{dp} p^4 &amp; = 4 p^3 &amp; = 0 + 0 p + 0 p^2 + 4 p^3 + \ldots
    &amp; = \langle 0, 0, 0, 4 \ldots \rangle
\end{aligned}
" /><br /></p>
<p>And so, in that <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?1%2C%20p%2C%20p%5E2%2C%20p%5E3%2C%20%5Cldots" alt="1, p, p^2, p^3, \ldots" title="1, p, p^2, p^3, \ldots" /> basis, the derivative of a polynomial can be represented as the matrix:</p>
<p><br /><img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?%0A%5Cfrac%7Bd%7D%7Bdp%7D%0A%5Csim%0A%5Cbegin%7Bbmatrix%7D%0A0%20%26%201%20%26%200%20%26%200%20%26%200%20%26%20%5Cldots%20%5C%5C%0A0%20%26%200%20%26%202%20%26%200%20%26%200%20%26%20%5Cldots%20%5C%5C%0A0%20%26%200%20%26%200%20%26%203%20%26%200%20%26%20%5Cldots%20%5C%5C%0A0%20%26%200%20%26%200%20%26%200%20%26%204%20%26%20%5Cldots%20%5C%5C%0A0%20%26%200%20%26%200%20%26%200%20%26%200%20%26%20%5Cldots%20%5C%5C%0A%5Cvdots%20%26%20%5Cvdots%20%26%20%5Cvdots%20%26%20%5Cvdots%20%26%20%5Cvdots%20%26%20%5Cddots%0A%5Cend%7Bbmatrix%7D%0A" alt="
\frac{d}{dp}
\sim
\begin{bmatrix}
0 &amp; 1 &amp; 0 &amp; 0 &amp; 0 &amp; \ldots \\
0 &amp; 0 &amp; 2 &amp; 0 &amp; 0 &amp; \ldots \\
0 &amp; 0 &amp; 0 &amp; 3 &amp; 0 &amp; \ldots \\
0 &amp; 0 &amp; 0 &amp; 0 &amp; 4 &amp; \ldots \\
0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; \ldots \\
\vdots &amp; \vdots &amp; \vdots &amp; \vdots &amp; \vdots &amp; \ddots
\end{bmatrix}
" title="
\frac{d}{dp}
\sim
\begin{bmatrix}
0 &amp; 1 &amp; 0 &amp; 0 &amp; 0 &amp; \ldots \\
0 &amp; 0 &amp; 2 &amp; 0 &amp; 0 &amp; \ldots \\
0 &amp; 0 &amp; 0 &amp; 3 &amp; 0 &amp; \ldots \\
0 &amp; 0 &amp; 0 &amp; 0 &amp; 4 &amp; \ldots \\
0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; \ldots \\
\vdots &amp; \vdots &amp; \vdots &amp; \vdots &amp; \vdots &amp; \ddots
\end{bmatrix}
" /><br /></p>
<p>No calculus required! (This is the core idea of the <a href="https://en.wikipedia.org/wiki/Formal_derivative">formal derivative</a> of a polynomial)</p>
<h2 id="matrix-operations">Matrix Operations</h2>
<p>In this light, we can understand the definition of the common matrix operations.</p>
<h3 id="matrix-vector-application">Matrix-Vector Application</h3>
<p>Matrix-vector application (or “multiplication”) is essentially the <em>decoding</em> of the linear transformation that the matrix represents.</p>
<p>Let’s look at the <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?2%20%5Ctimes%203" alt="2 \times 3" title="2 \times 3" /> example. Recall that we had:</p>
<p><br /><img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?%0Af%28%5Cmathbf%7Bx%7D%29%20%3D%20x_1%20f%28%5Cmathbf%7Bv%7D_1%29%20%2B%20x_2%20f%28%5Cmathbf%7Bv%7D_2%29%20%2B%20x_3%20f%28%5Cmathbf%7Bv%7D_3%29%0A" alt="
f(\mathbf{x}) = x_1 f(\mathbf{v}_1) + x_2 f(\mathbf{v}_2) + x_3 f(\mathbf{v}_3)
" title="
f(\mathbf{x}) = x_1 f(\mathbf{v}_1) + x_2 f(\mathbf{v}_2) + x_3 f(\mathbf{v}_3)
" /><br /></p>
<p>And we say that <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?f" alt="f" title="f" /> is completely defined by:</p>
<p><br /><img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Baligned%7D%0Af%28%5Cmathbf%7Bv%7D_1%29%20%26%20%3D%20a_%7B11%7D%20%5Cmathbf%7Bu%7D_1%20%2B%20a_%7B21%7D%20%5Cmathbf%7Bu%7D_2%20%5C%5C%0Af%28%5Cmathbf%7Bv%7D_2%29%20%26%20%3D%20a_%7B12%7D%20%5Cmathbf%7Bu%7D_1%20%2B%20a_%7B22%7D%20%5Cmathbf%7Bu%7D_2%20%5C%5C%0Af%28%5Cmathbf%7Bv%7D_3%29%20%26%20%3D%20a_%7B13%7D%20%5Cmathbf%7Bu%7D_1%20%2B%20a_%7B23%7D%20%5Cmathbf%7Bu%7D_2%0A%5Cend%7Baligned%7D%0A" alt="
\begin{aligned}
f(\mathbf{v}_1) &amp; = a_{11} \mathbf{u}_1 + a_{21} \mathbf{u}_2 \\
f(\mathbf{v}_2) &amp; = a_{12} \mathbf{u}_1 + a_{22} \mathbf{u}_2 \\
f(\mathbf{v}_3) &amp; = a_{13} \mathbf{u}_1 + a_{23} \mathbf{u}_2
\end{aligned}
" title="
\begin{aligned}
f(\mathbf{v}_1) &amp; = a_{11} \mathbf{u}_1 + a_{21} \mathbf{u}_2 \\
f(\mathbf{v}_2) &amp; = a_{12} \mathbf{u}_1 + a_{22} \mathbf{u}_2 \\
f(\mathbf{v}_3) &amp; = a_{13} \mathbf{u}_1 + a_{23} \mathbf{u}_2
\end{aligned}
" /><br /></p>
<p>This means that:</p>
<p><br /><img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Baligned%7D%0Af%28%5Cmathbf%7Bx%7D%29%20%26%20%3D%20x_1%20%28a_%7B11%7D%20%5Cmathbf%7Bu%7D_1%20%2B%20a_%7B21%7D%20%5Cmathbf%7Bu%7D_2%29%20%5C%5C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%26%20%2B%20x_2%20%28a_%7B12%7D%20%5Cmathbf%7Bu%7D_1%20%2B%20a_%7B22%7D%20%5Cmathbf%7Bu%7D_2%29%20%5C%5C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%26%20%2B%20x_3%20%28a_%7B13%7D%20%5Cmathbf%7Bu%7D_1%20%2B%20a_%7B23%7D%20%5Cmathbf%7Bu%7D_2%29%0A%5Cend%7Baligned%7D%0A" alt="
\begin{aligned}
f(\mathbf{x}) &amp; = x_1 (a_{11} \mathbf{u}_1 + a_{21} \mathbf{u}_2) \\
              &amp; + x_2 (a_{12} \mathbf{u}_1 + a_{22} \mathbf{u}_2) \\
              &amp; + x_3 (a_{13} \mathbf{u}_1 + a_{23} \mathbf{u}_2)
\end{aligned}
" title="
\begin{aligned}
f(\mathbf{x}) &amp; = x_1 (a_{11} \mathbf{u}_1 + a_{21} \mathbf{u}_2) \\
              &amp; + x_2 (a_{12} \mathbf{u}_1 + a_{22} \mathbf{u}_2) \\
              &amp; + x_3 (a_{13} \mathbf{u}_1 + a_{23} \mathbf{u}_2)
\end{aligned}
" /><br /></p>
<p>Which is itself a vector in <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?U" alt="U" title="U" />, so let’s write this as a combination of its components <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bu%7D_1" alt="\mathbf{u}_1" title="\mathbf{u}_1" /> and <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bu%7D_2" alt="\mathbf{u}_2" title="\mathbf{u}_2" />, by distributing and rearranging terms:</p>
<p><br /><img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Baligned%7D%0Af%28%5Cmathbf%7Bv%7D%29%20%26%20%3D%20%28v_1%20a_%7B11%7D%20%2B%20v_2%20a_%7B12%7D%20%2B%20v_3%20a_%7B13%7D%29%20%5Cmathbf%7Bu%7D_1%20%5C%5C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%26%20%2B%20%28v_1%20a_%7B21%7D%20%2B%20v_2%20a_%7B22%7D%20%2B%20v_3%20a_%7B23%7D%29%20%5Cmathbf%7Bu%7D_2%0A%5Cend%7Baligned%7D%0A" alt="
\begin{aligned}
f(\mathbf{v}) &amp; = (v_1 a_{11} + v_2 a_{12} + v_3 a_{13}) \mathbf{u}_1 \\
              &amp; + (v_1 a_{21} + v_2 a_{22} + v_3 a_{23}) \mathbf{u}_2
\end{aligned}
" title="
\begin{aligned}
f(\mathbf{v}) &amp; = (v_1 a_{11} + v_2 a_{12} + v_3 a_{13}) \mathbf{u}_1 \\
              &amp; + (v_1 a_{21} + v_2 a_{22} + v_3 a_{23}) \mathbf{u}_2
\end{aligned}
" /><br /></p>
<p>And this is exactly the formula for matrix-vector multiplication!</p>
<p><br /><img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bbmatrix%7D%0Aa_%7B11%7D%20%26%20a_%7B12%7D%20%26%20a_%7B13%7D%20%5C%5C%0Aa_%7B21%7D%20%26%20a_%7B22%7D%20%26%20a_%7B23%7D%0A%5Cend%7Bbmatrix%7D%0A%5Cbegin%7Bbmatrix%7D%0Ax_1%20%5C%5C%0Ax_2%20%5C%5C%0Ax_3%0A%5Cend%7Bbmatrix%7D%0A%3D%0A%5Cbegin%7Bbmatrix%7D%0Ax_1%20a_%7B11%7D%20%2B%20x_2%20a_%7B12%7D%20%2B%20x_3%20a_%7B13%7D%20%5C%5C%0Ax_1%20a_%7B21%7D%20%2B%20x_2%20a_%7B22%7D%20%2B%20x_3%20a_%7B23%7D%0A%5Cend%7Bbmatrix%7D%0A" alt="
\begin{bmatrix}
a_{11} &amp; a_{12} &amp; a_{13} \\
a_{21} &amp; a_{22} &amp; a_{23}
\end{bmatrix}
\begin{bmatrix}
x_1 \\
x_2 \\
x_3
\end{bmatrix}
=
\begin{bmatrix}
x_1 a_{11} + x_2 a_{12} + x_3 a_{13} \\
x_1 a_{21} + x_2 a_{22} + x_3 a_{23}
\end{bmatrix}
" title="
\begin{bmatrix}
a_{11} &amp; a_{12} &amp; a_{13} \\
a_{21} &amp; a_{22} &amp; a_{23}
\end{bmatrix}
\begin{bmatrix}
x_1 \\
x_2 \\
x_3
\end{bmatrix}
=
\begin{bmatrix}
x_1 a_{11} + x_2 a_{12} + x_3 a_{13} \\
x_1 a_{21} + x_2 a_{22} + x_3 a_{23}
\end{bmatrix}
" /><br /></p>
<p>Again, remember that what we are doing is manipulating <em>specific encodings</em> of our vectors and our linear transformations. Namely, we encode linear transformations as matrices, and vectors in their component encoding. The reason we can do these is that we agree upon a set of bases for our source and target vector spaces, and express these encodings in terms of those.</p>
<p>The magic we get out of this is that we can manipulate things in our “encoding world”, which correspond to things in the “real world”.</p>
<h3 id="addition-of-linear-transformations">Addition of linear transformations</h3>
<p>One neat thing about linear transformation is that they “add” well – you can add them together by simply applying them both and adding the results. The result is another linear transformation.</p>
<p><br /><img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?%0A%28f%20%2B%20g%29%28%5Cmathbf%7Bx%7D%29%20%5Cequiv%20f%28%5Cmathbf%7Bx%7D%29%20%2B%20g%28%5Cmathbf%7Bx%7D%29%0A" alt="
(f + g)(\mathbf{x}) \equiv f(\mathbf{x}) + g(\mathbf{x})
" title="
(f + g)(\mathbf{x}) \equiv f(\mathbf{x}) + g(\mathbf{x})
" /><br /></p>
<p>If <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?f%20%3A%20V%20%5Crightarrow%20U" alt="f : V \rightarrow U" title="f : V \rightarrow U" /> and <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?g%20%3A%20V%20%5Crightarrow%20U" alt="g : V \rightarrow U" title="g : V \rightarrow U" /> are linear transformations between the <em>same</em> vector spaces, then <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?f%20%2B%20g%20%3A%20V%20%5Crightarrow%20U" alt="f + g : V \rightarrow U" title="f + g : V \rightarrow U" />, as we defined it, is also one:</p>
<p><br /><img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Baligned%7D%0A%28f%20%2B%20g%29%28c%20%5Cmathbf%7Bx%7D%29%20%26%20%3D%20f%28c%20%5Cmathbf%7Bx%7D%29%20%2B%20g%28c%20%5Cmathbf%7Bx%7D%29%20%5C%5C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%26%20%3D%20c%20f%28%5Cmathbf%7Bx%7D%29%20%2B%20c%20g%28%5Cmathbf%7Bx%7D%29%20%5C%5C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%26%20%3D%20c%20%28%20f%28%5Cmathbf%7Bx%7D%29%20%2B%20g%28%5Cmathbf%7Bx%7D%29%20%29%20%5C%5C%0A%28f%20%2B%20g%29%28c%20%5Cmathbf%7Bx%7D%29%20%26%20%3D%20c%20%28f%20%2B%20g%29%28%5Cmathbf%7Bx%7D%29%0A%5Cend%7Baligned%7D%0A" alt="
\begin{aligned}
(f + g)(c \mathbf{x}) &amp; = f(c \mathbf{x}) + g(c \mathbf{x}) \\
                      &amp; = c f(\mathbf{x}) + c g(\mathbf{x}) \\
                      &amp; = c ( f(\mathbf{x}) + g(\mathbf{x}) ) \\
(f + g)(c \mathbf{x}) &amp; = c (f + g)(\mathbf{x})
\end{aligned}
" title="
\begin{aligned}
(f + g)(c \mathbf{x}) &amp; = f(c \mathbf{x}) + g(c \mathbf{x}) \\
                      &amp; = c f(\mathbf{x}) + c g(\mathbf{x}) \\
                      &amp; = c ( f(\mathbf{x}) + g(\mathbf{x}) ) \\
(f + g)(c \mathbf{x}) &amp; = c (f + g)(\mathbf{x})
\end{aligned}
" /><br /></p>
<p>(Showing that it respects addition is something you can look at if you want to have some fun!)</p>
<p>So, if <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?f" alt="f" title="f" /> is encoded as matrix <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?%5Chat%7BA%7D" alt="\hat{A}" title="\hat{A}" /> for given bases, and <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?g" alt="g" title="g" /> is encoded as matrix <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?%5Chat%7BB%7D" alt="\hat{B}" title="\hat{B}" />, what is the encoding of <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?f%20%2B%20g" alt="f + g" title="f + g" /> ?</p>
<p>Let’s say that, if <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?V" alt="V" title="V" /> and <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?U" alt="U" title="U" /> are 3-dimensional and 2-dimensional, respectively:</p>
<p><br /><img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Baligned%7D%0Af%28%5Cmathbf%7Bx%7D%29%20%26%20%3D%20%28x_1%20a_%7B11%7D%20%2B%20x_2%20a_%7B12%7D%20%2B%20x_3%20a_%7B13%7D%29%20%5Cmathbf%7Bu%7D_1%20%5C%5C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%26%20%2B%20%28x_1%20a_%7B21%7D%20%2B%20x_2%20a_%7B22%7D%20%2B%20x_3%20a_%7B23%7D%29%20%5Cmathbf%7Bu%7D_2%20%5C%5C%0Ag%28%5Cmathbf%7Bx%7D%29%20%26%20%3D%20%28x_1%20b_%7B11%7D%20%2B%20x_2%20b_%7B12%7D%20%2B%20x_3%20b_%7B13%7D%29%20%5Cmathbf%7Bu%7D_1%20%5C%5C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%26%20%2B%20%28x_1%20b_%7B21%7D%20%2B%20x_2%20b_%7B22%7D%20%2B%20x_3%20b_%7B23%7D%29%20%5Cmathbf%7Bu%7D_2%0A%5Cend%7Baligned%7D%0A" alt="
\begin{aligned}
f(\mathbf{x}) &amp; = (x_1 a_{11} + x_2 a_{12} + x_3 a_{13}) \mathbf{u}_1 \\
              &amp; + (x_1 a_{21} + x_2 a_{22} + x_3 a_{23}) \mathbf{u}_2 \\
g(\mathbf{x}) &amp; = (x_1 b_{11} + x_2 b_{12} + x_3 b_{13}) \mathbf{u}_1 \\
              &amp; + (x_1 b_{21} + x_2 b_{22} + x_3 b_{23}) \mathbf{u}_2
\end{aligned}
" title="
\begin{aligned}
f(\mathbf{x}) &amp; = (x_1 a_{11} + x_2 a_{12} + x_3 a_{13}) \mathbf{u}_1 \\
              &amp; + (x_1 a_{21} + x_2 a_{22} + x_3 a_{23}) \mathbf{u}_2 \\
g(\mathbf{x}) &amp; = (x_1 b_{11} + x_2 b_{12} + x_3 b_{13}) \mathbf{u}_1 \\
              &amp; + (x_1 b_{21} + x_2 b_{22} + x_3 b_{23}) \mathbf{u}_2
\end{aligned}
" /><br /></p>
<p>Then the breakdown of <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?f%20%2B%20g" alt="f + g" title="f + g" /> is:</p>
<p><br /><img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Baligned%7D%0A%28f%20%2B%20g%29%28%5Cmathbf%7Bv%7D%29%20%26%20%3D%20%28x_1%20a_%7B11%7D%20%2B%20x_2%20a_%7B12%7D%20%2B%20x_3%20a_%7B13%7D%29%20%5Cmathbf%7Bu%7D_1%20%5C%5C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%26%20%2B%20%28x_1%20a_%7B21%7D%20%2B%20x_2%20a_%7B22%7D%20%2B%20x_3%20a_%7B23%7D%29%20%5Cmathbf%7Bu%7D_2%20%5C%5C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%26%20%2B%20%28x_1%20b_%7B11%7D%20%2B%20x_2%20b_%7B12%7D%20%2B%20x_3%20b_%7B13%7D%29%20%5Cmathbf%7Bu%7D_1%20%5C%5C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%26%20%2B%20%28x_1%20b_%7B21%7D%20%2B%20x_2%20b_%7B22%7D%20%2B%20x_3%20b_%7B23%7D%29%20%5Cmathbf%7Bu%7D_2%20%5C%5C%0A%28f%20%2B%20g%29%28%5Cmathbf%7Bv%7D%29%20%26%20%3D%20%28x_1%20%5Ba_%7B11%7D%20%2B%20b_%7B11%7D%5D%20%2B%20x_2%20%5Ba_%7B12%7D%20%2B%20b_%7B12%7D%5D%20%2B%20x_3%20%5Ba_%7B13%7D%20%2B%20b_%7B13%7D%5D%29%20%5Cmathbf%7Bu%7D_1%20%5C%5C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%26%20%2B%20%28x_1%20%5Ba_%7B21%7D%20%2B%20b_%7B21%7D%5D%20%2B%20x_2%20%5Ba_%7B22%7D%20%2B%20b_%7B22%7D%5D%20%2B%20x_3%20%5Ba_%7B23%7D%20%2B%20b_%7B23%7D%5D%29%20%5Cmathbf%7Bu%7D_2%0A%5Cend%7Baligned%7D%0A" alt="
\begin{aligned}
(f + g)(\mathbf{v}) &amp; = (x_1 a_{11} + x_2 a_{12} + x_3 a_{13}) \mathbf{u}_1 \\
                    &amp; + (x_1 a_{21} + x_2 a_{22} + x_3 a_{23}) \mathbf{u}_2 \\
                    &amp; + (x_1 b_{11} + x_2 b_{12} + x_3 b_{13}) \mathbf{u}_1 \\
                    &amp; + (x_1 b_{21} + x_2 b_{22} + x_3 b_{23}) \mathbf{u}_2 \\
(f + g)(\mathbf{v}) &amp; = (x_1 [a_{11} + b_{11}] + x_2 [a_{12} + b_{12}] + x_3 [a_{13} + b_{13}]) \mathbf{u}_1 \\
                    &amp; + (x_1 [a_{21} + b_{21}] + x_2 [a_{22} + b_{22}] + x_3 [a_{23} + b_{23}]) \mathbf{u}_2
\end{aligned}
" title="
\begin{aligned}
(f + g)(\mathbf{v}) &amp; = (x_1 a_{11} + x_2 a_{12} + x_3 a_{13}) \mathbf{u}_1 \\
                    &amp; + (x_1 a_{21} + x_2 a_{22} + x_3 a_{23}) \mathbf{u}_2 \\
                    &amp; + (x_1 b_{11} + x_2 b_{12} + x_3 b_{13}) \mathbf{u}_1 \\
                    &amp; + (x_1 b_{21} + x_2 b_{22} + x_3 b_{23}) \mathbf{u}_2 \\
(f + g)(\mathbf{v}) &amp; = (x_1 [a_{11} + b_{11}] + x_2 [a_{12} + b_{12}] + x_3 [a_{13} + b_{13}]) \mathbf{u}_1 \\
                    &amp; + (x_1 [a_{21} + b_{21}] + x_2 [a_{22} + b_{22}] + x_3 [a_{23} + b_{23}]) \mathbf{u}_2
\end{aligned}
" /><br /></p>
<p>Note that if we say that <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?f%20%2B%20g" alt="f + g" title="f + g" /> is encoded as matrix <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?%5Chat%7BC%7D" alt="\hat{C}" title="\hat{C}" />, and call the components <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?c_%7B11%7D" alt="c_{11}" title="c_{11}" />, <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?c_%7B12%7D" alt="c_{12}" title="c_{12}" />, etc., then we can rewrite that as:</p>
<p><br /><img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Baligned%7D%0A%28f%20%2B%20g%29%28%5Cmathbf%7Bx%7D%29%20%26%20%3D%20%28x_1%20c_%7B11%7D%20%2B%20x_2%20c_%7B12%7D%20%2B%20x_3%20c_%7B13%7D%29%20%5Cmathbf%7Bu%7D_1%20%5C%5C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%26%20%2B%20%28x_1%20c_%7B21%7D%20%2B%20x_2%20c_%7B22%7D%20%2B%20x_3%20c_%7B23%7D%29%20%5Cmathbf%7Bu%7D_2%0A%5Cend%7Baligned%7D%0A" alt="
\begin{aligned}
(f + g)(\mathbf{x}) &amp; = (x_1 c_{11} + x_2 c_{12} + x_3 c_{13}) \mathbf{u}_1 \\
                    &amp; + (x_1 c_{21} + x_2 c_{22} + x_3 c_{23}) \mathbf{u}_2
\end{aligned}
" title="
\begin{aligned}
(f + g)(\mathbf{x}) &amp; = (x_1 c_{11} + x_2 c_{12} + x_3 c_{13}) \mathbf{u}_1 \\
                    &amp; + (x_1 c_{21} + x_2 c_{22} + x_3 c_{23}) \mathbf{u}_2
\end{aligned}
" /><br /></p>
<p>Where <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?c_%7B11%7D%20%3D%20a_%7B11%7D%20%2B%20b_%7B11%7D" alt="c_{11} = a_{11} + b_{11}" title="c_{11} = a_{11} + b_{11}" />, <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?c_%7B12%7D%20%3D%20a_%7B12%7D%20%2B%20b_%7B12%7D" alt="c_{12} = a_{12} + b_{12}" title="c_{12} = a_{12} + b_{12}" />, etc.</p>
<p>So, if <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?%5Chat%7BA%7D" alt="\hat{A}" title="\hat{A}" /> and <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?%5Chat%7BB%7D" alt="\hat{B}" title="\hat{B}" /> encode linear transformations <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?f" alt="f" title="f" /> and <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?g" alt="g" title="g" />, then we can encode <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?f%20%2B%20g" alt="f + g" title="f + g" /> as matrix <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?%5Chat%7BC%7D" alt="\hat{C}" title="\hat{C}" />, where the components of <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?%5Chat%7BC%7D" alt="\hat{C}" title="\hat{C}" /> are just the sum of their corresponding components in <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?%5Chat%7BA%7D" alt="\hat{A}" title="\hat{A}" /> and <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?%5Chat%7BB%7D" alt="\hat{B}" title="\hat{B}" />.</p>
<p>And that’s why we define <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?%5Chat%7BA%7D%20%2B%20%5Chat%7BB%7D" alt="\hat{A} + \hat{B}" title="\hat{A} + \hat{B}" />, matrix-matrix addition, as component-wise addition: component-wise addition perfectly “simulates” the addition of the linear transformation!</p>
<p>What’s happening here is we can represent manipulations of the functions themselves by manipulating <em>their encodings</em>.</p>
<p>And, again, the magic here is that, by manipulating things in our “encoding world”, we can make meaningful manipulations in the “real world” of linear transformations.</p>
<p><br /><img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bbmatrix%7D%0Aa_%7B11%7D%20%26%20a_%7B12%7D%20%26%20a_%7B13%7D%20%5C%5C%0Aa_%7B21%7D%20%26%20a_%7B22%7D%20%26%20a_%7B23%7D%0A%5Cend%7Bbmatrix%7D%0A%2B%0A%5Cbegin%7Bbmatrix%7D%0Ab_%7B11%7D%20%26%20b_%7B12%7D%20%26%20b_%7B13%7D%20%5C%5C%0Ab_%7B21%7D%20%26%20b_%7B22%7D%20%26%20b_%7B23%7D%0A%5Cend%7Bbmatrix%7D%0A%3D%0A%5Cbegin%7Bbmatrix%7D%0Aa_%7B11%7D%2Bb_%7B11%7D%20%26%20a_%7B12%7D%2Bb_%7B12%7D%20%26%20a_%7B13%7D%2Bb_%7B13%7D%20%5C%5C%0Aa_%7B21%7D%2Bb_%7B21%7D%20%26%20a_%7B22%7D%2Bb_%7B22%7D%20%26%20a_%7B23%7D%2Bb_%7B23%7D%0A%5Cend%7Bbmatrix%7D%0A" alt="
\begin{bmatrix}
a_{11} &amp; a_{12} &amp; a_{13} \\
a_{21} &amp; a_{22} &amp; a_{23}
\end{bmatrix}
+
\begin{bmatrix}
b_{11} &amp; b_{12} &amp; b_{13} \\
b_{21} &amp; b_{22} &amp; b_{23}
\end{bmatrix}
=
\begin{bmatrix}
a_{11}+b_{11} &amp; a_{12}+b_{12} &amp; a_{13}+b_{13} \\
a_{21}+b_{21} &amp; a_{22}+b_{22} &amp; a_{23}+b_{23}
\end{bmatrix}
" title="
\begin{bmatrix}
a_{11} &amp; a_{12} &amp; a_{13} \\
a_{21} &amp; a_{22} &amp; a_{23}
\end{bmatrix}
+
\begin{bmatrix}
b_{11} &amp; b_{12} &amp; b_{13} \\
b_{21} &amp; b_{22} &amp; b_{23}
\end{bmatrix}
=
\begin{bmatrix}
a_{11}+b_{11} &amp; a_{12}+b_{12} &amp; a_{13}+b_{13} \\
a_{21}+b_{21} &amp; a_{22}+b_{22} &amp; a_{23}+b_{23}
\end{bmatrix}
" /><br /></p>
<p>Symbolically, if we write function application as matrix-vector multiplication, we say that <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?%5Chat%7BA%7D%20%2B%20%5Chat%7BB%7D" alt="\hat{A} + \hat{B}" title="\hat{A} + \hat{B}" /> is defined so that <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?%28%5Chat%7BA%7D%20%2B%20%5Chat%7BB%7D%29%5Cmathbf%7Bx%7D%20%3D%20%5Chat%7BA%7D%20%5Cmathbf%7Bx%7D%20%2B%20%5Chat%7BB%7D%20%5Cmathbf%7Bx%7D" alt="(\hat{A} + \hat{B})\mathbf{x} = \hat{A} \mathbf{x} + \hat{B} \mathbf{x}" title="(\hat{A} + \hat{B})\mathbf{x} = \hat{A} \mathbf{x} + \hat{B} \mathbf{x}" />.</p>
<h3 id="multiplication-of-linear-transformations">Multiplication of linear transformations</h3>
<p>We might be tempted to define <em>multiplication</em> of linear transformations the same way. However, this doesn’t quite make sense.</p>
<p>Remember that we talked about adding linear transformations as the addition of their results. However, we can’t talk about multiplying linear transformations as the multiplication of their results because the idea of a vector space doesn’t come with any notion of multiplication.</p>
<p>However, even if we talk specifically about linear transformations to <em>scalars</em>, this still doesn’t quite work:</p>
<p><br /><img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Baligned%7D%0A%28f%20%2A%20g%29%28c%20%5Cmathbf%7Bx%7D%29%20%26%20%3D%20f%28c%20%5Cmathbf%7Bx%7D%29%20g%28c%20%5Cmathbf%7Bx%7D%29%20%5C%5C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%26%20%3D%20c%20f%28%5Cmathbf%7Bx%7D%29%20c%20g%28%5Cmathbf%7Bx%7D%29%20%5C%5C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%26%20%3D%20c%5E2%20%28%20f%28%5Cmathbf%7Bx%7D%29%20g%28%5Cmathbf%7Bx%7D%29%20%29%20%5C%5C%0A%28f%20%2A%20g%29%28c%20%5Cmathbf%7Bx%7D%29%20%26%20%3D%20c%5E2%20%28f%20%2A%20g%29%28%5Cmathbf%7Bx%7D%29%0A%5Cend%7Baligned%7D%0A" alt="
\begin{aligned}
(f * g)(c \mathbf{x}) &amp; = f(c \mathbf{x}) g(c \mathbf{x}) \\
                      &amp; = c f(\mathbf{x}) c g(\mathbf{x}) \\
                      &amp; = c^2 ( f(\mathbf{x}) g(\mathbf{x}) ) \\
(f * g)(c \mathbf{x}) &amp; = c^2 (f * g)(\mathbf{x})
\end{aligned}
" title="
\begin{aligned}
(f * g)(c \mathbf{x}) &amp; = f(c \mathbf{x}) g(c \mathbf{x}) \\
                      &amp; = c f(\mathbf{x}) c g(\mathbf{x}) \\
                      &amp; = c^2 ( f(\mathbf{x}) g(\mathbf{x}) ) \\
(f * g)(c \mathbf{x}) &amp; = c^2 (f * g)(\mathbf{x})
\end{aligned}
" /><br /></p>
<p>So, <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?%28f%20%2A%20g%29%28c%20%5Cmathbf%7Bx%7D%29%20%3D%20c%5E2%20%28f%20%2A%20g%29%28%5Cmathbf%7Bx%7D%29" alt="(f * g)(c \mathbf{x}) = c^2 (f * g)(\mathbf{x})" title="(f * g)(c \mathbf{x}) = c^2 (f * g)(\mathbf{x})" />. Therefore, <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?f%20%2A%20g" alt="f * g" title="f * g" />, defined point-wise, does <em>not</em> yield a linear transformation.</p>
<p>Therefore, <em>there is no matrix</em> that could would even represent or encode <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?f%20%2A%20g" alt="f * g" title="f * g" />, as we defined it. So, since <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?f%20%2A%20g" alt="f * g" title="f * g" /> isn’t even representable as a matrix in our encoding scheme, it doesn’t make sense to treat it as a matrix operation. There’s no possible result!</p>
<h3 id="composition-of-linear-transformations">Composition of linear transformations</h3>
<p>Since linear transformations are functions, we can compose them:</p>
<p><br /><img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?%0A%28f%20%5Ccirc%20g%29%28%5Cmathbf%7Bx%7D%29%20%5Cequiv%20f%28g%28%5Cmathbf%7Bx%7D%29%29%0A" alt="
(f \circ g)(\mathbf{x}) \equiv f(g(\mathbf{x}))
" title="
(f \circ g)(\mathbf{x}) \equiv f(g(\mathbf{x}))
" /><br /></p>
<p>Is the composition of linear transformations also a linear transformation?</p>
<p><br /><img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Baligned%7D%0A%28f%20%5Ccirc%20g%29%28c%20%5Cmathbf%7Bx%7D%29%20%26%20%3D%20f%28g%28c%20%5Cmathbf%7Bx%7D%29%29%20%5C%5C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%26%20%3D%20f%28c%20g%28%5Cmathbf%7Bx%7D%29%29%20%5C%5C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%26%20%3D%20c%20f%28g%28%5Cmathbf%7Bx%7D%29%29%20%5C%5C%0A%28f%20%5Ccirc%20g%29%28c%20%5Cmathbf%7Bx%7D%29%20%26%20%3D%20c%20%28f%20%5Ccirc%20g%29%28%5Cmathbf%7Bx%7D%29%0A%5Cend%7Baligned%7D%0A" alt="
\begin{aligned}
(f \circ g)(c \mathbf{x}) &amp; = f(g(c \mathbf{x})) \\
                      &amp; = f(c g(\mathbf{x})) \\
                      &amp; = c f(g(\mathbf{x})) \\
(f \circ g)(c \mathbf{x}) &amp; = c (f \circ g)(\mathbf{x})
\end{aligned}
" title="
\begin{aligned}
(f \circ g)(c \mathbf{x}) &amp; = f(g(c \mathbf{x})) \\
                      &amp; = f(c g(\mathbf{x})) \\
                      &amp; = c f(g(\mathbf{x})) \\
(f \circ g)(c \mathbf{x}) &amp; = c (f \circ g)(\mathbf{x})
\end{aligned}
" /><br /></p>
<p>Yes! (Well, once you prove that it respects addition. I’ll leave the fun to you!)</p>
<p>Okay, so we know that <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?f%20%5Ccirc%20g" alt="f \circ g" title="f \circ g" /> is indeed a linear transformation. That means that it can <em>also</em> be encoded as a matrix.</p>
<p>So, let’s say that <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?f%20%3A%20U%20%5Crightarrow%20W" alt="f : U \rightarrow W" title="f : U \rightarrow W" />, then <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?g%20%3A%20V%20%5Crightarrow%20U" alt="g : V \rightarrow U" title="g : V \rightarrow U" />. <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?f" alt="f" title="f" /> is a linear transformation from <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?U" alt="U" title="U" /> to <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?W" alt="W" title="W" />, and <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?g" alt="g" title="g" /> is a linear transformation from <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?V" alt="V" title="V" /> to <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?U" alt="U" title="U" />. That means that <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?f%20%5Ccirc%20g%20%3A%20V%20%5Crightarrow%20W" alt="f \circ g : V \rightarrow W" title="f \circ g : V \rightarrow W" /> is a linear transformation from <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?V" alt="V" title="V" /> to <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?W" alt="W" title="W" />. It goes from <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?V" alt="V" title="V" />, through <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?U" alt="U" title="U" />, and all the way to <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?W" alt="W" title="W" />.</p>
<p>Let’s say that <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?V" alt="V" title="V" /> is 3-dimensional, <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?U" alt="U" title="U" /> is 2-dimensional, and <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?W" alt="W" title="W" /> is 4-dimensional.</p>
<p>If <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?f" alt="f" title="f" /> is encoded by the <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?4%20%5Ctimes%202" alt="4 \times 2" title="4 \times 2" /> matrix <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?%5Chat%7BA%7D" alt="\hat{A}" title="\hat{A}" />, and <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?g" alt="g" title="g" /> is encoded by <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?2%20%5Ctimes%203" alt="2 \times 3" title="2 \times 3" /> matrix <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?%5Chat%7BB%7D" alt="\hat{B}" title="\hat{B}" />, then we can represent <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?f%20%5Ccirc%20g" alt="f \circ g" title="f \circ g" /> as the <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?4%20%5Ctimes%203" alt="4 \times 3" title="4 \times 3" /> matrix <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?%5Chat%7BC%7D" alt="\hat{C}" title="\hat{C}" />.</p>
<p>If you’ve taken a linear algebra class, you might recognize this pattern. Combining a <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?4%20%5Ctimes%202" alt="4 \times 2" title="4 \times 2" /> and a <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?2%20%5Ctimes%203" alt="2 \times 3" title="2 \times 3" /> to make a <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?4%20%5Ctimes%203" alt="4 \times 3" title="4 \times 3" /> ?</p>
<p>We <em>can</em> compute <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?%5Chat%7BC%7D" alt="\hat{C}" title="\hat{C}" /> using only the encodings <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?%5Chat%7BA%7D" alt="\hat{A}" title="\hat{A}" /> and <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?%5Chat%7BB%7D" alt="\hat{B}" title="\hat{B}" />! We call this <strong>matrix multiplication</strong>. It’s typically denoted as <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?%5Chat%7BC%7D%20%3D%20%5Chat%7BA%7D%20%5Chat%7BB%7D" alt="\hat{C} = \hat{A} \hat{B}" title="\hat{C} = \hat{A} \hat{B}" />.</p>
<p>That’s exactly what <em>matrix multiplication</em> is defined as. If:</p>
<ul>
<li><img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?%5Chat%7BA%7D" alt="\hat{A}" title="\hat{A}" /> is a <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?O%20%5Ctimes%20M" alt="O \times M" title="O \times M" /> matrix representing a linear transformation from a M-dimensional space to an O-dimensional space</li>
<li><img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?%5Chat%7BB%7D" alt="\hat{B}" title="\hat{B}" /> is an <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?M%20%5Ctimes%20N" alt="M \times N" title="M \times N" /> matrix representing a linear transformation from an N-dimensional space to an M-dimensional space</li>
</ul>
<p>Then:</p>
<ul>
<li><img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?%5Chat%7BC%7D%20%3D%20%5Chat%7BA%7D%5Chat%7BB%7D" alt="\hat{C} = \hat{A}\hat{B}" title="\hat{C} = \hat{A}\hat{B}" /> is a <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?O%20%5Ctimes%20N" alt="O \times N" title="O \times N" /> matrix representing a linear transformation from an N-dimensional space to an O-dimensional space.</li>
</ul>
<p>Again – manipulation of our <em>encodings</em> can manifest the manipulation in the <em>linear transformations</em> that we want.</p>
<p>Symbolically, if we treat function application as matrix-vector multiplication, this means that <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?%5Chat%7BA%7D%5Chat%7BB%7D" alt="\hat{A}\hat{B}" title="\hat{A}\hat{B}" /> is defined such that <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?%28%5Chat%7BA%7D%5Chat%7BB%7D%29%5Cmathbf%7Bx%7D%20%3D%20%5Chat%7BA%7D%28%5Chat%7BB%7D%5Cmathbf%7Bx%7D%29" alt="(\hat{A}\hat{B})\mathbf{x} = \hat{A}(\hat{B}\mathbf{x})" title="(\hat{A}\hat{B})\mathbf{x} = \hat{A}(\hat{B}\mathbf{x})" />.</p>
<p>In that notation, it kinda looks like the associativity of multiplication, doesn’t it? Don’t be fooled! <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?%5Chat%7BA%7D%20%5Chat%7BB%7D" alt="\hat{A} \hat{B}" title="\hat{A} \hat{B}" />, matrix-matrix multiplication, is a completely different type of operation than <img style="vertical-align:middle" src="https://latex.codecogs.com/png.latex?%5Chat%7BB%7D%5Cmathbf%7Bv%7D" alt="\hat{B}\mathbf{v}" title="\hat{B}\mathbf{v}" />. One is the symbolic manipulation on <em>two encodings</em> of of a linear transformation, and the other is an <em>application</em> of an encoding of a linear transformation on encoding of a vector.</p>
<p>If you’re familiar with Haskell idioms, matrix-matrix multiplication is like <code>.</code> (function composition), and matrix-vector multiplication is like <code>$</code>, or function application. One is a “higher order function”: taking two functions (at least, the encodings of them) and returning a new function. The other is an application of a function to its input.</p>
<p>And, like in Haskell:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode haskell"><code class="sourceCode haskell"><a class="sourceLine" id="cb1-1" data-line-number="1">(f <span class="fu">.</span> g) x <span class="fu">=</span> f (g x)</a></code></pre></div>
<p>We won’t go over the actual process of computing the matrix-matrix product, but it’s something that you can work out just in terms of the definitions of the encodings. Just manually apply out everything and group together common factors of the basis vectors of the destination space.</p>
<h2 id="the-big-picture">The Big Picture</h2>
<p>At the highest level here, what we’re doing is taking a <em>function</em> and encoding it as <em>data</em> – a parameterization of that function. Essentially, we take the properties of the type of functions we are looking at and find out that it can be defined/represented in a limited number of parameters</p>
<p>Then, the breakthrough is that we look at useful higher-order functions and manipulations of those transformations. Then, we see how we can implement those <em>transformations</em> by symbolically manipulating the <em>encodings</em>!</p>
<p>This is actually a dance we do all the time in programming. Instead of working with functions, we work with reified data that represent those functions. And, instead of direct higher order functions, we transform that data in a way that makes it encodes the function we want to produce.</p>
<p>Matrices are exactly that. Linear transformations are the functions we want to analyze, and we realize that we can completely specify/define any linear transformation with a matrix (against a choice of bases).</p>
<p>Then, we realize that there are some nice manipulations we can do on linear transformations; we can combine them to create new linear transformations in useful ways.</p>
<p>However, because those manipulations all produce <em>new</em> linear transformations, we know that their results can all be encoded in <em>new</em> matrices. So, we see if we can just directly apply those manipulations by directly working on those matrices!</p>
<p>I hope this post serves to demystify matrices, matrix addition, and multiplication for you, and help you see why they are defined the way that they are. Furthermore, I hope that it gives some insight on why matrices are useful in linear algebra, and also how similar encodings can help you with manipulating other types of functions!</p></div><footer><ul class="entry-series"></ul><ul class="tag-list"><li><a href="https://blog.jle.im/entries/tagged/linear-algebra.html" class="tag-a-tag">#linear algebra</a></li><li><a href="https://blog.jle.im/entries/category/@math.html" class="tag-a-category">@MATH</a></li></ul><aside class="social-buttons"><div class="addthis_toolbox addthis_default_style addthis-buttons"><a class="addthis_button_facebook_like" fb:like:layout="button_count"></a><a class="addthis_button_tweet"></a><a class="addthis_button_google_plusone" g:plusone:size="medium"></a><a class="addthis_counter addthis_pill_style"></a></div><div class="custom-social-buttons"><div class="custom-social-button"><a href="https://www.reddit.com/submit" onclick="window.location = &#39;https://www.reddit.com/submit?url=&#39;+ encodeURIComponent(window.location); return false"><img src="https://www.reddit.com/static/spreddit7.gif" alt="submit to reddit"></a></div></div></aside><nav class="next-prev-links"><ul><li class="prev-entry-link">&larr; <a href="https://blog.jle.im/entry/introducing-the-backprop-library.html">Introducing the backprop library</a> (Previous)</li><li class="next-entry-link">(Next) <a href="https://blog.jle.im/entry/const-applicative-and-monoids.html">The Const Applicative and Monoids</a> &rarr;</li></ul></nav></footer></article><div class="post-entry"><div class="tile"><div id="disqus_thread"></div><script type="text/javascript">var disqus_config = function () {
    this.page.url = 'https://blog.jle.im/entry/you-could-have-invented-matrices.html';
    this.page.identifier = 'invent-matrices';
};
(function() {
    var d = document, s = d.createElement('script');
    s.src = '//incode.disqus.com/embed.js';
    s.setAttribute('data-timestamp', +new Date());
    (d.head || d.body).appendChild(s);
})();
</script><noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a><br></noscript><a href="http://disqus.com" class="dsq-brlink">Comments powered by <span class="logo-disqus">Disqus</span></a></div></div></div></div></div><div id="footer-container"><div id="footer-content"><div class="tile"><div class="footer-copyright">&copy; 2018 Justin Le</div><div class="footer-follow social-follows"><ul class="social-follows-list"><li><ul class="social-follows-list-social"><li><a class="social-follow-twitter" title="Follow me on Twitter!" href="https://twitter.com/intent/user?user_id=mstk" onclick="window.open(
  &#39;http://twitter.com/intent/user?user_id=907281&#39;,
  &#39;facebook-share-dialog&#39;,
  &#39;width=550,height=520&#39;);
return false;
">Twitter</a></li><li><a class="social-follow-gplus" title="Add me on Google+!" href="https://plus.google.com/+JustinLe">Google+</a></li><li><a class="social-follow-linkedin" title="Connect with me on LinkedIn!" href="https://linkedin.com/in/lejustin">LinkedIn</a></li><li><a class="social-follow-github" title="Fork me on Github!" href="https://github.com/mstksg">Github</a></li><li><a class="social-follow-keybase" title="Track me on Keybase!" href="https://keybase.io/mstksg">Keybase</a></li><li><a class="social-follow-bitcoin" title="Donate via bitcoin!" href="https://coinbase.com/mstksg">Bitcoin</a></li></ul></li><li><ul class="social-follows-list-site"><li><a class="social-follow-rss" title="Subscribe to my RSS Feed!" href="http://feeds.feedburner.com/incodeblog">RSS</a></li><li><a class="social-follow-email" title="Subscribe to the mailing list!" href="https://feedburner.google.com/fb/a/mailverify?loc=en_US&amp;uri=incodeblog">Mailing list</a></li></ul></li></ul></div></div></div></div></body></html>