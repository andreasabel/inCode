\documentclass[]{article}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\usepackage{fixltx2e} % provides \textsubscript
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
\else % if luatex or xelatex
  \ifxetex
    \usepackage{mathspec}
    \usepackage{xltxtra,xunicode}
  \else
    \usepackage{fontspec}
  \fi
  \defaultfontfeatures{Mapping=tex-text,Scale=MatchLowercase}
  \newcommand{\euro}{â‚¬}
\fi
% use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
% use microtype if available
\IfFileExists{microtype.sty}{\usepackage{microtype}}{}
\usepackage[margin=1in]{geometry}
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\newenvironment{Shaded}{}{}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{#1}}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.49,0.56,0.16}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.53,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.56,0.13,0.00}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.73,0.13,0.13}{\textit{#1}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.02,0.16,0.49}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.40,0.40,0.40}{#1}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.74,0.48,0.00}{#1}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.73,0.40,0.53}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.10,0.09,0.49}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{#1}}}}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
\ifxetex
  \usepackage[setpagesize=false, % page size defined by xetex
              unicode=false, % unicode breaks when used with xetex
              xetex]{hyperref}
\else
  \usepackage[unicode=true]{hyperref}
\fi
\hypersetup{breaklinks=true,
            bookmarks=true,
            pdfauthor={Justin Le},
            pdftitle={Automatic Propagation of Uncertainty with AD},
            colorlinks=true,
            citecolor=blue,
            urlcolor=blue,
            linkcolor=magenta,
            pdfborder={0 0 0}}
\urlstyle{same}  % don't use monospace font for urls
% Make links footnotes instead of hotlinks:
\renewcommand{\href}[2]{#2\footnote{\url{#1}}}
\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt plus 2pt minus 1pt}
\setlength{\emergencystretch}{3em}  % prevent overfull lines
\setcounter{secnumdepth}{0}

\title{Automatic Propagation of Uncertainty with AD}
\author{Justin Le}
\date{May 9, 2016}

\begin{document}
\maketitle

\emph{Originally posted on
\textbf{\href{https://blog.jle.im/entry/automatic-propagation-of-uncertainty-with-ad.html}{in
Code}}.}

\begin{quote}
This post and \href{https://blog.jle.im/entries/series/+uncertain.html}{series}
is a walk-through of the implementation of my
\emph{\href{https://hackage.haskell.org/package/uncertain}{uncertain}} library,
now on hackage!
\end{quote}

Some of my favorite Haskell ``tricks'' involve working with exotic numeric types
with custom ``overloaded'' numeric functions and literals that let us work with
data in surprisingly elegant and expressive ways.

Here is one example --- from my work in experimental physics and statistics, we
often deal with experimental/sampled values with inherent uncertainty. If you
ever measure something to be
\includegraphics{https://latex.codecogs.com/png.latex?12.3\%5C\%2C\%5Cmathrm\%7Bcm\%7D},
that doesn't mean it's
\includegraphics{https://latex.codecogs.com/png.latex?12.300000\%5C\%2C\%5Cmathrm\%7Bcm\%7D}
--- it means that it's somewhere between
\includegraphics{https://latex.codecogs.com/png.latex?12.2\%5C\%2C\%5Cmathrm\%7Bcm\%7D}
and
\includegraphics{https://latex.codecogs.com/png.latex?12.4\%5C\%2C\%5Cmathrm\%7Bcm\%7D}\ldots{}and
we don't know exactly. We can write it as
\includegraphics{https://latex.codecogs.com/png.latex?12.3\%20\%5Cpm\%200.1\%5C\%2C\%5Cmathrm\%7Bcm\%7D}.
The interesting thing happens when we try to add, multiply, divide numbers with
uncertainty. What happens when you ``add''
\includegraphics{https://latex.codecogs.com/png.latex?12\%20\%5Cpm\%203} and
\includegraphics{https://latex.codecogs.com/png.latex?19\%20\%5Cpm\%206}?

The initial guess might be
\includegraphics{https://latex.codecogs.com/png.latex?31\%20\%5Cpm\%209},
because one is
\includegraphics{https://latex.codecogs.com/png.latex?\%5Cpm\%203} and the other
is \includegraphics{https://latex.codecogs.com/png.latex?\%5Cpm\%206}. But! If
you actually do experiments like this several times, you'll see that this isn't
the case. If you tried this out experimentally and simulate several hundred
trials, you'll see that the answer is actually something like
\includegraphics{https://latex.codecogs.com/png.latex?31\%20\%5Cpm\%207}. (We'll
explain why later, but feel free to stop reading this article now and try this
out yourself!\footnote{You can simulate noisy data by using uniform noise
  distributions, Gaussian distributions, or however manner you like that has a
  given expected value (mean) and ``spread''. Verify by checking the
  \href{https://en.wikipedia.org/wiki/Standard_deviation}{standard deviation} of
  the sums!})

Let's write ourselves a Haskell data type that lets us work with ``numbers with
inherent uncertainty'':

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ghci}\FunctionTok{>} \KeywordTok{let}\NormalTok{ x }\FunctionTok{=} \FloatTok{14.6} \FunctionTok{+/-} \FloatTok{0.8}
\NormalTok{ghci}\FunctionTok{>} \KeywordTok{let}\NormalTok{ y }\FunctionTok{=} \DecValTok{31}   \FunctionTok{+/-} \DecValTok{2}
\NormalTok{ghci}\FunctionTok{>}\NormalTok{ x }\FunctionTok{+}\NormalTok{ y}
\DecValTok{46} \FunctionTok{+/-} \DecValTok{2}
\NormalTok{ghci}\FunctionTok{>}\NormalTok{ x }\FunctionTok{*}\NormalTok{ y}
\DecValTok{450} \FunctionTok{+/-} \DecValTok{40}
\NormalTok{ghci}\FunctionTok{>}\NormalTok{ sqrt (x }\FunctionTok{+}\NormalTok{ y)}
\FloatTok{6.8} \FunctionTok{+/-} \FloatTok{0.2}
\NormalTok{ghci}\FunctionTok{>}\NormalTok{ logBase y x}
\FloatTok{0.78} \FunctionTok{+/-} \FloatTok{0.02}
\NormalTok{ghci}\FunctionTok{>}\NormalTok{ log (x}\FunctionTok{**}\NormalTok{y)}
\FloatTok{85.9} \FunctionTok{+/-} \FloatTok{0.3}
\end{Highlighting}
\end{Shaded}

Along the way, we'll also learn how to harness the power of awesome
\href{https://hackage.haskell.org/package/ad}{ad} library, a library used in
implementing back-propagation and other optimization algorithms, to analyze
numerical functions in a mathematical way and break down their derivatives and
gradients.

You can follow along with
\href{https://github.com/mstksg/inCode/tree/master/code-samples/uncertain/Uncertain.hs}{the
source code}, which is actually a
\emph{\href{http://www.haskellstack.org}{stack}} executable! If you download the
source and you have \emph{\href{http://www.haskellstack.org}{stack}} installed,
you can run it (and run the tests above) as an executable:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{$ }\ExtensionTok{./Uncertain.hs}
\end{Highlighting}
\end{Shaded}

Otherwise, you can run it directly with stack (using \texttt{runhaskell}) and
the
\href{shttp://hackage.haskell.org/package/linear/docs/Linear-V2.html}{linear}
and \href{https://hackage.haskell.org/package/ad}{ad} packages
installed\ldots{}or load it up with \texttt{stack\ ghci} to play with it. If you
want to be sure to reproduce the behavior, this article was written under
\href{https://www.stackage.org/}{stackage} snapshot
\href{https://www.stackage.org/lts-5.15}{lts-5.15}.

\hypertarget{dealing-with-uncertainty-precisely}{%
\section{Dealing with Uncertainty
Precisely}\label{dealing-with-uncertainty-precisely}}

First of all, let's think about why adding two ``uncertain'' values doesn't
involve simply adding the uncertainties linearly. (If you don't care about the
math and just want to get on to the Haskell, feel free to skip this section!)

If I have a value
\includegraphics{https://latex.codecogs.com/png.latex?16\%20\%5Cpm\%203} (maybe
I have a ruler whose ticks are 3 units apart, or an instrument that produces
measurements with 3 units of noise), it either means that it's a little below 16
or a little above 16. If I have an independently sampled value
\includegraphics{https://latex.codecogs.com/png.latex?25\%20\%5Cpm\%204}, it
means that it's a little below 25 or a little above 25.

What happens if I want to think about their sum? Well, it's going to be
somewhere around 41. But, the uncertainty won't be
\includegraphics{https://latex.codecogs.com/png.latex?\%5Cpm\%207}. It would
only be \includegraphics{https://latex.codecogs.com/png.latex?\%5Cpm\%207} if
the errors in the two values are \emph{always aligned}. Only if or when every
``little bit above'' 16 error lines up perfectly with a ``little bit above'' 25
error, and when every single ``little bit below'' 16 error lines up perfectly
with a ``little bit above'' 25 error, would you really get something that is
\includegraphics{https://latex.codecogs.com/png.latex?\%5Cpm\%207}. But, because
the two values are sampled independently, you shouldn't expect such alignment.
So, you'll get an uncertainty that's \emph{less than}
\includegraphics{https://latex.codecogs.com/png.latex?\%5Cpm\%207}. In fact,
it'll actually be around
\includegraphics{https://latex.codecogs.com/png.latex?\%5Cpm\%205}.

In general, we find that for \emph{independent}
\includegraphics{https://latex.codecogs.com/png.latex?X} and
\includegraphics{https://latex.codecogs.com/png.latex?Y}:

{[} \textbackslash{}operatorname\{Var\}{[}aX + bY + c{]} = a\^{}2
\textbackslash{}sigma\_X\^{}2 + b\^{}2
\textbackslash{}sigma\_Y\^{}2{]}(https://latex.codecogs.com/png.latex?\%0A\%5Coperatorname\%7BVar\%7D\%5BaX\%20\%2B\%20bY\%20\%2B\%20c\%5D\%20\%3D\%20a\%5E2\%20\%5Csigma\_X\%5E2\%20\%2B\%20b\%5E2\%20\%5Csigma\_Y\%5E2\%0A
" \operatorname{Var}{[}aX + bY + c{]} = a\^{}2 \sigma\_X\^{}2 + b\^{}2
\sigma\_Y\^{}2 ")

Where \includegraphics{https://latex.codecogs.com/png.latex?\%5Csigma_X\%5E2} is
the variance in \includegraphics{https://latex.codecogs.com/png.latex?X}. We
consider \includegraphics{https://latex.codecogs.com/png.latex?\%5Csigma_X} to
be the standard deviation of
\includegraphics{https://latex.codecogs.com/png.latex?X}, or the ``plus or
minus'' part of our numbers. In the simple case of addition, we have
\includegraphics{https://latex.codecogs.com/png.latex?\%5Coperatorname\%7BVar\%7D\%5BX\%20\%2B\%20Y\%5D\%20\%3D\%20\%5Csigma_X\%5E2\%20\%2B\%20\%5Csigma_Y\%5E2},
so our new uncertainty\footnote{This law actually comes from the mathematical
  \emph{definition} of variance, so does not assume anything about the
  underlying distribution of the sampling --- just that they are independent,
  and that they have defined variances.} is
\includegraphics{https://latex.codecogs.com/png.latex?\%5Csqrt\%7B\%5Csigma_X\%5E2\%20\%2B\%20\%5Csigma_Y\%5E2\%7D}.

However, not all functions that combine
\includegraphics{https://latex.codecogs.com/png.latex?X} and
\includegraphics{https://latex.codecogs.com/png.latex?Y} can be expressed as
simple linear combinations
\includegraphics{https://latex.codecogs.com/png.latex?aX\%20\%2B\%20bY\%20\%2B\%20c}.
But! If you dig back to your days of high school calculus, you might remember a
method for expressing any arbitrary function as a linear approximation -- the
\href{https://en.wikipedia.org/wiki/Taylor_series}{Taylor Expansion}!

In general, we can attempt to approximate any well-behaving function around a
point as its tangent hyperplane:

{[} f(x\_0 + x, y\_0 + y) \textbackslash{}approx f\_x(x\_0, y\_0) x + f\_y(x\_0,
y\_0) y + f(x\_0,
y\_0){]}(https://latex.codecogs.com/png.latex?\%0Af\%28x\_0\%20\%2B\%20x\%2C\%20y\_0\%20\%2B\%20y\%29\%20\%5Capprox\%20f\_x\%28x\_0\%2C\%20y\_0\%29\%20x\%20\%2B\%20f\_y\%28x\_0\%2C\%20y\_0\%29\%20y\%20\%2B\%20f\%28x\_0\%2C\%20y\_0\%29\%0A
" f(x\_0 + x, y\_0 + y) \approx f\_x(x\_0, y\_0) x + f\_y(x\_0, y\_0) y +
f(x\_0, y\_0) ")

Where
\includegraphics{https://latex.codecogs.com/png.latex?f_x\%28x_0\%2Cy_0\%29} is
the first (partial) derivative with respect to
\includegraphics{https://latex.codecogs.com/png.latex?x} at
\includegraphics{https://latex.codecogs.com/png.latex?\%28x_0\%2C\%20y_0\%29}.
This gives us an approximation of
\includegraphics{https://latex.codecogs.com/png.latex?f} at locations close to
\includegraphics{https://latex.codecogs.com/png.latex?\%28x_0\%2C\%20y_0\%29}.

Look familiar? This is exactly the form that we used earlier to calculate
``combined'' variance! If we approximate the functions around
\includegraphics{https://latex.codecogs.com/png.latex?\%28\%5Cmu_X\%2C\%20\%5Cmu_Y\%29},
the center/expected value of
\includegraphics{https://latex.codecogs.com/png.latex?X} and
\includegraphics{https://latex.codecogs.com/png.latex?Y}, we see:

{[} \textbackslash{}operatorname\{Var\}{[}f(X,Y){]} \textbackslash{}approx
f\_x(\textbackslash{}mu\_X, \textbackslash{}mu\_Y)\^{}2
\textbackslash{}sigma\_X\^{}2 +
f\_y(\textbackslash{}mu\_X,\textbackslash{}mu\_Y)\^{}2
\textbackslash{}sigma\_Y\^{}2{]}(https://latex.codecogs.com/png.latex?\%0A\%5Coperatorname\%7BVar\%7D\%5Bf\%28X\%2CY\%29\%5D\%20\%5Capprox\%20f\_x\%28\%5Cmu\_X\%2C\%20\%5Cmu\_Y\%29\%5E2\%20\%5Csigma\_X\%5E2\%20\%2B\%20f\_y\%28\%5Cmu\_X\%2C\%5Cmu\_Y\%29\%5E2\%20\%5Csigma\_Y\%5E2\%0A
" \operatorname{Var}{[}f(X,Y){]} \approx f\_x(\mu\_X, \mu\_Y)\^{}2
\sigma\_X\^{}2 + f\_y(\mu\_X,\mu\_Y)\^{}2 \sigma\_Y\^{}2 ")

A similar analysis can be used to figure out how the expected value changes by
taking the taylor expansion to the \emph{second} degree:

{[} \textbackslash{}operatorname\{E\}{[}f(X,Y){]} \textbackslash{}approx
f(\textbackslash{}mu\_X, \textbackslash{}mu\_Y) + \textbackslash{}frac\{1\}\{2\}
\textbackslash{}left{[} f\_\{xx\}(\textbackslash{}mu\_X, \textbackslash{}mu\_Y)
\textbackslash{}sigma\_X\^{}2 + f\_\{yy\}(\textbackslash{}mu\_X,
\textbackslash{}mu\_Y) \textbackslash{}sigma\_Y\^{}2
\textbackslash{}right{]}{]}(https://latex.codecogs.com/png.latex?\%0A\%5Coperatorname\%7BE\%7D\%5Bf\%28X\%2CY\%29\%5D\%20\%5Capprox\%0Af\%28\%5Cmu\_X\%2C\%20\%5Cmu\_Y\%29\%20\%2B\%20\%5Cfrac\%7B1\%7D\%7B2\%7D\%0A\%5Cleft\%5B\%20f\_\%7Bxx\%7D\%28\%5Cmu\_X\%2C\%20\%5Cmu\_Y\%29\%20\%5Csigma\_X\%5E2\%20\%2B\%20f\_\%7Byy\%7D\%28\%5Cmu\_X\%2C\%20\%5Cmu\_Y\%29\%20\%5Csigma\_Y\%5E2\%20\%5Cright\%5D\%0A
" \operatorname{E}{[}f(X,Y){]} \approx f(\mu\_X, \mu\_Y) + \frac{1}{2}
\left[ f_{xx}(\mu_X, \mu_Y) \sigma_X^2 + f_{yy}(\mu_X, \mu_Y) \sigma_Y^2 \right]")

Where
\includegraphics{https://latex.codecogs.com/png.latex?f_\%7Bxx\%7D\%28\%5Cmu_X\%2C\%20\%5Cmu_Y\%29}
is the second (partial) derivative with respect to
\includegraphics{https://latex.codecogs.com/png.latex?x} twice at
\includegraphics{https://latex.codecogs.com/png.latex?\%28\%5Cmu_X\%2C\%20\%5Cmu_Y\%29}

For our case of simple addition,
\includegraphics{https://latex.codecogs.com/png.latex?\%5Coperatorname\%7BE\%7D\%5BX\%20\%2B\%20Y\%5D\%20\%3D\%20\%5Cmu_X\%20\%2B\%20\%5Cmu_Y},
because the second-order partials of
\includegraphics{https://latex.codecogs.com/png.latex?f\%28x\%2Cy\%29\%20\%3D\%20x\%20\%2B\%20y}
are 0.

\hypertarget{uncertain-values-in-haskell}{%
\section{Uncertain Values in Haskell}\label{uncertain-values-in-haskell}}

So, how are we going to model our uncertain values in Haskell \ldots{} ? With an
Algebraic Data Type, of course!

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{-- source: https://github.com/mstksg/inCode/tree/master/code-samples/uncertain/Uncertain.hs#L18-L20}

\KeywordTok{data} \DataTypeTok{Uncert}\NormalTok{ a }\FunctionTok{=} \DataTypeTok{Un}\NormalTok{ \{}\OtherTok{ uMean ::} \FunctionTok{!}\NormalTok{a}
\NormalTok{                   ,}\OtherTok{ uVar  ::} \FunctionTok{!}\NormalTok{a}
\NormalTok{                   \}}
\end{Highlighting}
\end{Shaded}

We'll keep track of the mean (the central point) and the \emph{variance}, which
is the standard deviation \emph{squared}. We keep track of the variance and not
the standard deviation (the ``plus or minus'') because the mathematics is a bit
more straightforward.

We can write a function to turn a ``plus or minus'' statement into an
\texttt{Uncert}:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{-- source: https://github.com/mstksg/inCode/tree/master/code-samples/uncertain/Uncertain.hs#L22-L23}

\OtherTok{(+/-) ::} \DataTypeTok{Num}\NormalTok{ a }\OtherTok{=>}\NormalTok{ a }\OtherTok{->}\NormalTok{ a }\OtherTok{->} \DataTypeTok{Uncert}\NormalTok{ a}
\NormalTok{x }\FunctionTok{+/-}\NormalTok{ dx }\FunctionTok{=} \DataTypeTok{Un}\NormalTok{ x (dx}\FunctionTok{*}\NormalTok{dx)}
\end{Highlighting}
\end{Shaded}

Give the \texttt{dx} (the standard deviation) and store \texttt{dx\^{}2}, the
variance.

Let's also throw in a handy helper function for ``exact'' values:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{-- source: https://github.com/mstksg/inCode/tree/master/code-samples/uncertain/Uncertain.hs#L25-L26}

\OtherTok{exact ::} \DataTypeTok{Num}\NormalTok{ a }\OtherTok{=>}\NormalTok{ a }\OtherTok{->} \DataTypeTok{Uncert}\NormalTok{ a}
\NormalTok{exact x }\FunctionTok{=}\NormalTok{ x }\FunctionTok{+/-} \DecValTok{0}
\end{Highlighting}
\end{Shaded}

But, we can do better (if just for fun). We can use pattern synonyms to
basically ``abstract'' away the data type itself, and let people pattern match
on a mean and standard deviation:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{-- source: https://github.com/mstksg/inCode/tree/master/code-samples/uncertain/Uncertain.hs#L29-L34}

\CommentTok{-- pattern (:+/-) :: () => Floating a => a -> a -> Uncert a}
\CommentTok{-- [GHC 8.0:]}
\CommentTok{-- pattern (:+/-) :: Floating a => a -> a -> Uncert a}
\NormalTok{pattern x }\FunctionTok{:+/-}\NormalTok{ dx }\OtherTok{<-} \DataTypeTok{Un}\NormalTok{ x (sqrt}\OtherTok{->}\NormalTok{dx)}
  \KeywordTok{where}
\NormalTok{    x }\FunctionTok{:+/-}\NormalTok{ dx }\FunctionTok{=} \DataTypeTok{Un}\NormalTok{ x (dx}\FunctionTok{*}\NormalTok{dx)}
\end{Highlighting}
\end{Shaded}

(Note that the type signature you need for this is different depending on if
you're in GHC 8.0 and GHC 7.10; they're mutually incompatible. How unfortunate!)

Now, people can pattern match on \texttt{x\ :+/-\ dx} and receive the mean and
uncertainty directly. Neat!

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{-- source: https://github.com/mstksg/inCode/tree/master/code-samples/uncertain/Uncertain.hs#L36-L37}

\OtherTok{uStdev ::} \DataTypeTok{Floating}\NormalTok{ a }\OtherTok{=>} \DataTypeTok{Uncert}\NormalTok{ a }\OtherTok{->}\NormalTok{ a}
\NormalTok{uStdev (_ }\FunctionTok{:+/-}\NormalTok{ dx) }\FunctionTok{=}\NormalTok{ dx}
\end{Highlighting}
\end{Shaded}

\hypertarget{making-it-numeric}{%
\subsection{Making it Numeric}\label{making-it-numeric}}

Now, time for the magic! Let's write a \texttt{Num} instance!

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{instance} \DataTypeTok{Num}\NormalTok{ a }\OtherTok{=>} \DataTypeTok{Num}\NormalTok{ (}\DataTypeTok{Uncert}\NormalTok{ a) }\KeywordTok{where}
\NormalTok{    fromIntegral      }\FunctionTok{=}\NormalTok{ exact }\FunctionTok{.}\NormalTok{ fromIntegral}
    \DataTypeTok{Un}\NormalTok{ x vx }\FunctionTok{+} \DataTypeTok{Un}\NormalTok{ y vy }\FunctionTok{=} \DataTypeTok{Un}\NormalTok{ (x }\FunctionTok{+}\NormalTok{ y)    (vx }\FunctionTok{+}\NormalTok{ vy)}
    \DataTypeTok{Un}\NormalTok{ x vx }\FunctionTok{-} \DataTypeTok{Un}\NormalTok{ y vy }\FunctionTok{=} \DataTypeTok{Un}\NormalTok{ (x }\FunctionTok{-}\NormalTok{ y)    (vx }\FunctionTok{+}\NormalTok{ vy)}
    \DataTypeTok{Un}\NormalTok{ x vx }\FunctionTok{*} \DataTypeTok{Un}\NormalTok{ y vy }\FunctionTok{=} \DataTypeTok{Un}\NormalTok{ (x }\FunctionTok{*}\NormalTok{ y)    (y}\FunctionTok{^}\DecValTok{2} \FunctionTok{*}\NormalTok{ vx }\FunctionTok{+}\NormalTok{ x}\FunctionTok{^}\DecValTok{2} \FunctionTok{*}\NormalTok{ vy)}
\NormalTok{    negate (}\DataTypeTok{Un}\NormalTok{ x vx)  }\FunctionTok{=} \DataTypeTok{Un}\NormalTok{ (negate x) vx}
    \CommentTok{-- ...}
\end{Highlighting}
\end{Shaded}

And\ldots{}that's it! Do the same thing for every numeric typeclass, and you get
automatic propagation of uncertainty.

\hypertarget{the-problem}{%
\subsection{The Problem}\label{the-problem}}

But, wait --- this method is definitely not ideal. It's pretty repetitive, and
involves a but of copy-and-pasting code that is slightly different in ways the
typechecker can't verify. What if we didn't change something we were supposed
to? And, if you look at the \texttt{Fractional} instance\ldots{}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{instance} \DataTypeTok{Fractional}\NormalTok{ a }\OtherTok{=>} \DataTypeTok{Fractional}\NormalTok{ (}\DataTypeTok{Uncert}\NormalTok{ a) }\KeywordTok{where}
\NormalTok{    fromRational      }\FunctionTok{=}\NormalTok{ exact }\FunctionTok{.}\NormalTok{ fromRational}
    \DataTypeTok{Un}\NormalTok{ x vx }\FunctionTok{/} \DataTypeTok{Un}\NormalTok{ y vy }\FunctionTok{=} \DataTypeTok{Un}\NormalTok{ (x}\FunctionTok{/}\NormalTok{y }\FunctionTok{+}\NormalTok{ x}\FunctionTok{/}\NormalTok{y}\FunctionTok{^}\DecValTok{3}\FunctionTok{*}\NormalTok{vy)   (x}\FunctionTok{^}\DecValTok{2}\FunctionTok{/}\NormalTok{y}\FunctionTok{^}\DecValTok{4}\FunctionTok{*}\NormalTok{vx }\FunctionTok{+}\NormalTok{ vy}\FunctionTok{/}\NormalTok{y}\FunctionTok{^}\DecValTok{2}\NormalTok{)}
\NormalTok{    recip (}\DataTypeTok{Un}\NormalTok{ x vx)   }\FunctionTok{=} \DataTypeTok{Un}\NormalTok{ (recip x }\FunctionTok{+}\NormalTok{ vx}\FunctionTok{/}\NormalTok{x}\FunctionTok{^}\DecValTok{3}\NormalTok{) (vx }\FunctionTok{/}\NormalTok{ x}\FunctionTok{^}\DecValTok{4}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Yikes. All that ugly and complicated numerical code that the typechecker can't
help us with (and, honestly, I'm not very confident in the results myself!).
Those are runtime bugs just waiting to happen. How do we even \emph{know} that
we calculated the right derivatives, and implemented the formula correctly?

What if we could reduce this boilerplate? What if we could somehow analytically
compute derivatives for functions instead of computing them manually?

\hypertarget{automatic-differentiation}{%
\section{Automatic Differentiation}\label{automatic-differentiation}}

Automatic differentiation is honestly one of the coolest Haskell tricks you can
show that any beginner can immediately understand. Like our trick with
\texttt{Uncert}, it's nice to use because of its overloaded \texttt{Num}/numeric
typeclasses.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ghci}\FunctionTok{>}\NormalTok{ diff (\textbackslash{}x }\OtherTok{->}\NormalTok{ x}\FunctionTok{^}\DecValTok{2}\NormalTok{) }\DecValTok{10}       \CommentTok{-- 2*x}
\DecValTok{20}
\NormalTok{ghci}\FunctionTok{>}\NormalTok{ diff (\textbackslash{}x }\OtherTok{->}\NormalTok{ sin x) }\DecValTok{0}      \CommentTok{-- cos x}
\FloatTok{1.0}
\NormalTok{ghci}\FunctionTok{>}\NormalTok{ diff (\textbackslash{}x }\OtherTok{->}\NormalTok{ x}\FunctionTok{^}\DecValTok{3} \FunctionTok{-} \DecValTok{3}\FunctionTok{*}\NormalTok{x}\FunctionTok{^}\DecValTok{2} \FunctionTok{+} \DecValTok{2}\FunctionTok{*}\NormalTok{x }\FunctionTok{-} \DecValTok{4}\NormalTok{) }\DecValTok{3}  \CommentTok{-- 3*x^2 - 6*x + 2}
\DecValTok{11}
\end{Highlighting}
\end{Shaded}

A very rough explanation about how forward-mode automatic differentiation works
is that it uses a wrapper type (like ours) that defines \texttt{*},
\texttt{negate}, etc. so that they also compute the \emph{derivative(s)} of the
function, instead of just the \emph{result}, like normal. There are a lot of
nice tutorials online, like \href{http://www.danielbrice.net/blog/10/}{this one}
by Daniel Brice, if you want to follow up on this fun little subject.

\hypertarget{single-variable-functions}{%
\subsection{Single-variable functions}\label{single-variable-functions}}

And, now that we can automatically differentiate functions, we can use this
knowledge directly in our implementations. Let's define a universal ``lifter''
of single-variable functions.

We use the function \texttt{diffs0} to get a ``tower'' of derivatives:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ghci}\FunctionTok{>}\NormalTok{ diffs0 (\textbackslash{}x }\OtherTok{->}\NormalTok{ x}\FunctionTok{^}\DecValTok{2} \FunctionTok{-} \DecValTok{2}\NormalTok{ x}\FunctionTok{^}\DecValTok{3}\NormalTok{) }\DecValTok{4}
\NormalTok{[}\FunctionTok{-}\DecValTok{112}\NormalTok{, }\FunctionTok{-}\DecValTok{88}\NormalTok{, }\FunctionTok{-}\DecValTok{46}\NormalTok{, }\FunctionTok{-}\DecValTok{12}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{0}\FunctionTok{...}
\end{Highlighting}
\end{Shaded}

The first value is actually
\includegraphics{https://latex.codecogs.com/png.latex?4\%5E2\%20-\%202\%20\%5Ctimes\%204\%5E3}.
The second is the derivative
(\includegraphics{https://latex.codecogs.com/png.latex?2\%20x\%20-\%206x\%5E2})
at 4, the third is the second derivative
\includegraphics{https://latex.codecogs.com/png.latex?2\%20-\%2012\%20x} at 4,
then the third derivative
\includegraphics{https://latex.codecogs.com/png.latex?-12}, then the fourth
derivative \includegraphics{https://latex.codecogs.com/png.latex?0}, etc.

We only need the actual value and the first two derivatives, so we can pattern
match them as \texttt{fx:dfx:ddfx:\_\ =\ diffs0\ f\ x}, the derivatives and
values of the function we lift, \texttt{f}, around the mean \texttt{x}.

At that point, the equations we have from before just translate nicely:

{[} \textbackslash{}operatorname\{E\}{[}f(X){]} = f(\textbackslash{}mu\_X) +
\textbackslash{}frac\{1\}\{2\} f\_\{xx\}(\textbackslash{}mu\_X)
\textbackslash{}sigma\_X\^{}2{]}(https://latex.codecogs.com/png.latex?\%0A\%5Coperatorname\%7BE\%7D\%5Bf\%28X\%29\%5D\%20\%3D\%20f\%28\%5Cmu\_X\%29\%20\%2B\%20\%5Cfrac\%7B1\%7D\%7B2\%7D\%20f\_\%7Bxx\%7D\%28\%5Cmu\_X\%29\%20\%5Csigma\_X\%5E2\%0A
" \operatorname{E}{[}f(X){]} = f(\mu\emph{X) + \frac{1}{2} f}\{xx\}(\mu\_X)
\sigma\_X\^{}2 ")

{[} \textbackslash{}operatorname\{Var\}{[}f(X){]} =
f\_x(\textbackslash{}mu\_X)\^{}2
\textbackslash{}sigma\_X\^{}2{]}(https://latex.codecogs.com/png.latex?\%0A\%5Coperatorname\%7BVar\%7D\%5Bf\%28X\%29\%5D\%20\%3D\%20f\_x\%28\%5Cmu\_X\%29\%5E2\%20\%5Csigma\_X\%5E2\%0A
" \operatorname{Var}{[}f(X){]} = f\_x(\mu\_X)\^{}2 \sigma\_X\^{}2 ")

And we call \includegraphics{https://latex.codecogs.com/png.latex?\%5Cmu_X}
\texttt{x} and
\includegraphics{https://latex.codecogs.com/png.latex?\%5Csigma_X\%5E2}
\texttt{vx}, and this becomes:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{y  }\FunctionTok{=}\NormalTok{ fx }\FunctionTok{+}\NormalTok{ ddfx }\FunctionTok{*}\NormalTok{ vx }\FunctionTok{/} \DecValTok{2}
\NormalTok{vy }\FunctionTok{=}\NormalTok{ dfx}\FunctionTok{^}\DecValTok{2} \FunctionTok{*}\NormalTok{ vx}
\end{Highlighting}
\end{Shaded}

Putting it all together:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{-- source: https://github.com/mstksg/inCode/tree/master/code-samples/uncertain/Uncertain.hs#L39-L47}

\OtherTok{liftU ::} \DataTypeTok{Fractional}\NormalTok{ a}
      \OtherTok{=>}\NormalTok{ (forall s}\FunctionTok{.} \DataTypeTok{AD}\NormalTok{ s (}\DataTypeTok{Tower}\NormalTok{ a) }\OtherTok{->} \DataTypeTok{AD}\NormalTok{ s (}\DataTypeTok{Tower}\NormalTok{ a))}
      \OtherTok{->} \DataTypeTok{Uncert}\NormalTok{ a}
      \OtherTok{->} \DataTypeTok{Uncert}\NormalTok{ a}
\NormalTok{liftU f (}\DataTypeTok{Un}\NormalTok{ x vx) }\FunctionTok{=} \DataTypeTok{Un}\NormalTok{ y vy}
  \KeywordTok{where}
\NormalTok{    fx}\FunctionTok{:}\NormalTok{dfx}\FunctionTok{:}\NormalTok{ddfx}\FunctionTok{:}\NormalTok{_ }\FunctionTok{=}\NormalTok{ diffs0 f x}
\NormalTok{    y             }\FunctionTok{=}\NormalTok{ fx }\FunctionTok{+}\NormalTok{ ddfx }\FunctionTok{*}\NormalTok{ vx }\FunctionTok{/} \DecValTok{2}
\NormalTok{    vy            }\FunctionTok{=}\NormalTok{ dfx}\FunctionTok{^}\DecValTok{2} \FunctionTok{*}\NormalTok{ vx}
\end{Highlighting}
\end{Shaded}

The type
\texttt{forall\ s.\ AD\ s\ (Tower\ a)\ -\textgreater{}\ AD\ s\ (Tower\ a)} looks
a little scary, but you can think of it as representing a function on \texttt{a}
(like \texttt{negate}, \texttt{(*2)}, etc.) that the \emph{ad} library can
differentiate several times --- something you could use with \texttt{diff0} to
get a ``tower'' of derivatives.

And \ldots{} that's it! We can already define things like:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{negate }\FunctionTok{=}\NormalTok{ liftU negate}
\NormalTok{recip  }\FunctionTok{=}\NormalTok{ liftU recip}
\NormalTok{sqrt   }\FunctionTok{=}\NormalTok{ liftU sqrt}
\NormalTok{sin    }\FunctionTok{=}\NormalTok{ liftU sin}
\end{Highlighting}
\end{Shaded}

\hypertarget{multivariable-functions}{%
\subsection{Multivariable functions}\label{multivariable-functions}}

\emph{ad} also lets you work multivariable functions, too. To model
multivariable functions, it takes a function from a \texttt{Traversable} of
vales to a single value. We can use the \texttt{V2} type from the
\emph{\href{shttp://hackage.haskell.org/package/linear/docs/Linear-V2.html}{linear}}
package to pass in a two-variable function:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ghci}\FunctionTok{>}\NormalTok{ grad (\textbackslash{}(}\DataTypeTok{V2}\NormalTok{ x y) }\OtherTok{->}\NormalTok{ x }\FunctionTok{*}\NormalTok{ y}\FunctionTok{^}\DecValTok{2} \FunctionTok{+} \DecValTok{3}\FunctionTok{*}\NormalTok{x) (}\DataTypeTok{V2} \DecValTok{3} \DecValTok{1}\NormalTok{)}
\DataTypeTok{V2} \DecValTok{4} \DecValTok{6}
\end{Highlighting}
\end{Shaded}

The gradient of
\includegraphics{https://latex.codecogs.com/png.latex?f\%28x\%2C\%20y\%29\%20\%3D\%20x\%20y\%5E2\%20\%2B\%203x}
is
\includegraphics{https://latex.codecogs.com/png.latex?\%28y\%5E2\%20\%2B\%203\%2C\%202xy\%29},
which, at
\includegraphics{https://latex.codecogs.com/png.latex?\%283\%2C\%201\%29}, is
indeed
\includegraphics{https://latex.codecogs.com/png.latex?\%284\%2C\%206\%29}.

The gradient gives us the first order partials, but we need the second order
partials to calculate the new mean, so for that, we can use \texttt{hessian}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ghci}\FunctionTok{>}\NormalTok{ hessian (\textbackslash{}(}\DataTypeTok{V2}\NormalTok{ x y) }\OtherTok{->}\NormalTok{ x }\FunctionTok{*}\NormalTok{ y}\FunctionTok{^}\DecValTok{2} \FunctionTok{+} \DecValTok{3}\FunctionTok{*}\NormalTok{x) (}\DataTypeTok{V2} \DecValTok{3} \DecValTok{1}\NormalTok{)}
\DataTypeTok{V2}\NormalTok{ (}\DataTypeTok{V2} \DecValTok{0} \DecValTok{2}\NormalTok{)}
\NormalTok{   (}\DataTypeTok{V2} \DecValTok{2} \DecValTok{6}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

The \href{https://en.wikipedia.org/wiki/Hessian_matrix}{hessian} of a function
\includegraphics{https://latex.codecogs.com/png.latex?f\%28x\%2Cy\%29} is
basically a matrix of second-order partial derivatives:

{[} \textbackslash{}begin\{bmatrix\} f\_\{xx\}(x, y) \& f\_\{yx\}(x, y)
\textbackslash{}\textbackslash{} f\_\{yx\}(x, y) \& f\_\{yy\}(x, y)
\textbackslash{}end\{bmatrix\}{]}(https://latex.codecogs.com/png.latex?\%0A\%5Cbegin\%7Bbmatrix\%7D\%0Af\_\%7Bxx\%7D\%28x\%2C\%20y\%29\%20\%26\%20f\_\%7Byx\%7D\%28x\%2C\%20y\%29\%20\%5C\%5C\%0Af\_\%7Byx\%7D\%28x\%2C\%20y\%29\%20\%26\%20f\_\%7Byy\%7D\%28x\%2C\%20y\%29\%0A\%5Cend\%7Bbmatrix\%7D\%0A
" \textbackslash{}begin\{bmatrix\} f\_\{xx\}(x, y) \& f\_\{yx\}(x, y)
\textbackslash{} f\_\{yx\}(x, y) \& f\_\{yy\}(x, y)
\textbackslash{}end\{bmatrix\} ")

In our case, we only care about the diagonal -- the repeated double-derivatives,
\includegraphics{https://latex.codecogs.com/png.latex?f_\%7Bxx\%7D} and
\includegraphics{https://latex.codecogs.com/png.latex?f_\%7Byy\%7D}. Indeed, the
double-partial of our function respect to
\includegraphics{https://latex.codecogs.com/png.latex?x} is
\includegraphics{https://latex.codecogs.com/png.latex?0}, and the double-partial
with respect to \includegraphics{https://latex.codecogs.com/png.latex?y} is
\includegraphics{https://latex.codecogs.com/png.latex?2x}, which gives us a
hessian with a diagonal
\includegraphics{https://latex.codecogs.com/png.latex?\%280\%2C\%206\%29} for
the input
\includegraphics{https://latex.codecogs.com/png.latex?\%283\%2C\%201\%29}.

The \emph{ad} package generously gives us a function that lets us calculate the
function's result, its gradient, and its hessian all in one pass:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ghci}\FunctionTok{>}\NormalTok{ hessian' (\textbackslash{}(}\DataTypeTok{V2}\NormalTok{ x y) }\OtherTok{->}\NormalTok{ x }\FunctionTok{*}\NormalTok{ y}\FunctionTok{^}\DecValTok{2} \FunctionTok{+} \DecValTok{3}\FunctionTok{*}\NormalTok{x) (}\DataTypeTok{V2} \DecValTok{3} \DecValTok{1}\NormalTok{)}
\NormalTok{(}\DecValTok{12}\NormalTok{, }\DataTypeTok{V2}\NormalTok{ (}\DecValTok{4}\NormalTok{, }\DataTypeTok{V2} \DecValTok{0} \DecValTok{3}\NormalTok{)}
     \DataTypeTok{V2}\NormalTok{ (}\DecValTok{6}\NormalTok{, }\DataTypeTok{V2} \DecValTok{2} \DecValTok{6}\NormalTok{)}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

We can access the gradient by using \texttt{fmap\ fst} on the second component
of the tuple and access the hessian by using \texttt{fmap\ snd}.

We need a couple of helpers, first --- one to get the ``diagonal'' of our
hessian, because we only care about the repeated partials:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{-- source: https://github.com/mstksg/inCode/tree/master/code-samples/uncertain/Uncertain.hs#L49-L53}

\OtherTok{diag ::}\NormalTok{ [[a]] }\OtherTok{->}\NormalTok{ [a]}
\NormalTok{diag }\FunctionTok{=}\NormalTok{ \textbackslash{}}\KeywordTok{case}
\NormalTok{    []        }\OtherTok{->}\NormalTok{ []}
\NormalTok{    []   }\FunctionTok{:}\NormalTok{yss }\OtherTok{->}\NormalTok{ diag (drop }\DecValTok{1} \FunctionTok{<$>}\NormalTok{ yss)}
\NormalTok{    (x}\FunctionTok{:}\NormalTok{_)}\FunctionTok{:}\NormalTok{yss }\OtherTok{->}\NormalTok{ x }\FunctionTok{:}\NormalTok{ diag (drop }\DecValTok{1} \FunctionTok{<$>}\NormalTok{ yss)}
\end{Highlighting}
\end{Shaded}

And then a ``dot product'', utility function, which just multiplies two lists
together component-by-component and sums the results:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{-- source: https://github.com/mstksg/inCode/tree/master/code-samples/uncertain/Uncertain.hs#L55-L56}

\OtherTok{dot ::} \DataTypeTok{Num}\NormalTok{ a }\OtherTok{=>}\NormalTok{ [a] }\OtherTok{->}\NormalTok{ [a] }\OtherTok{->}\NormalTok{ a}
\NormalTok{dot xs ys }\FunctionTok{=}\NormalTok{ sum (zipWith (}\FunctionTok{*}\NormalTok{) xs ys)}
\end{Highlighting}
\end{Shaded}

And now we can write our multi-variate function lifter:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{-- source: https://github.com/mstksg/inCode/tree/master/code-samples/uncertain/Uncertain.hs#L58-L75}

\OtherTok{liftUF ::}\NormalTok{ (}\DataTypeTok{Traversable}\NormalTok{ f, }\DataTypeTok{Fractional}\NormalTok{ a)}
       \OtherTok{=>}\NormalTok{ (forall s}\FunctionTok{.}\NormalTok{ f (}\DataTypeTok{AD}\NormalTok{ s (}\DataTypeTok{Sparse}\NormalTok{ a)) }\OtherTok{->} \DataTypeTok{AD}\NormalTok{ s (}\DataTypeTok{Sparse}\NormalTok{ a))}
       \OtherTok{->}\NormalTok{ f (}\DataTypeTok{Uncert}\NormalTok{ a)}
       \OtherTok{->} \DataTypeTok{Uncert}\NormalTok{ a}
\NormalTok{liftUF f us }\FunctionTok{=} \DataTypeTok{Un}\NormalTok{ y vy}
  \KeywordTok{where}
\NormalTok{    xs          }\FunctionTok{=}\NormalTok{         uMean }\FunctionTok{<$>}\NormalTok{ us}
\NormalTok{    vxs         }\FunctionTok{=}\NormalTok{ toList (uVar  }\FunctionTok{<$>}\NormalTok{ us)}
\NormalTok{    (fx, hgrad) }\FunctionTok{=}\NormalTok{ hessian' f xs}
\NormalTok{    dfxs        }\FunctionTok{=}\NormalTok{ fst }\FunctionTok{<$>}\NormalTok{ hgrad}
\NormalTok{    hess        }\FunctionTok{=}\NormalTok{ snd }\FunctionTok{<$>}\NormalTok{ hgrad}
\NormalTok{    y           }\FunctionTok{=}\NormalTok{ fx }\FunctionTok{+}\NormalTok{ partials }\FunctionTok{/} \DecValTok{2}
      \KeywordTok{where}
\NormalTok{        partials }\FunctionTok{=}\NormalTok{ dot vxs}
                 \FunctionTok{.}\NormalTok{ diag}
                 \FunctionTok{$}\NormalTok{ toList (fmap toList hess) }\CommentTok{-- from f (f a) to [[a]]}
\NormalTok{    vy          }\FunctionTok{=}\NormalTok{ dot vxs}
                \FunctionTok{$}\NormalTok{ toList ((}\FunctionTok{^}\DecValTok{2}\NormalTok{) }\FunctionTok{<$>}\NormalTok{ dfxs)}
\end{Highlighting}
\end{Shaded}

(Again, don't mind the scary type
\texttt{forall\ s.\ f\ (AD\ s\ (Sparse\ a))\ -\textgreater{}\ AD\ s\ (Sparse\ a)},
it's just \emph{ad}'s type for things you can use
\texttt{hessian\textquotesingle{}} on)

And we can write some nice helper functions so we can use them more naturally:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{-- source: https://github.com/mstksg/inCode/tree/master/code-samples/uncertain/Uncertain.hs#L77-L90}

\OtherTok{liftU2 ::} \DataTypeTok{Fractional}\NormalTok{ a}
       \OtherTok{=>}\NormalTok{ (forall s}\FunctionTok{.} \DataTypeTok{AD}\NormalTok{ s (}\DataTypeTok{Sparse}\NormalTok{ a) }\OtherTok{->} \DataTypeTok{AD}\NormalTok{ s (}\DataTypeTok{Sparse}\NormalTok{ a) }\OtherTok{->} \DataTypeTok{AD}\NormalTok{ s (}\DataTypeTok{Sparse}\NormalTok{ a))}
       \OtherTok{->} \DataTypeTok{Uncert}\NormalTok{ a}
       \OtherTok{->} \DataTypeTok{Uncert}\NormalTok{ a}
       \OtherTok{->} \DataTypeTok{Uncert}\NormalTok{ a}
\NormalTok{liftU2 f x y }\FunctionTok{=}\NormalTok{ liftUF (\textbackslash{}(}\DataTypeTok{V2}\NormalTok{ x' y') }\OtherTok{->}\NormalTok{ f x' y') (}\DataTypeTok{V2}\NormalTok{ x y)}

\OtherTok{liftU3 ::} \DataTypeTok{Fractional}\NormalTok{ a}
       \OtherTok{=>}\NormalTok{ (forall s}\FunctionTok{.} \DataTypeTok{AD}\NormalTok{ s (}\DataTypeTok{Sparse}\NormalTok{ a) }\OtherTok{->} \DataTypeTok{AD}\NormalTok{ s (}\DataTypeTok{Sparse}\NormalTok{ a) }\OtherTok{->} \DataTypeTok{AD}\NormalTok{ s (}\DataTypeTok{Sparse}\NormalTok{ a) }\OtherTok{->} \DataTypeTok{AD}\NormalTok{ s (}\DataTypeTok{Sparse}\NormalTok{ a))}
       \OtherTok{->} \DataTypeTok{Uncert}\NormalTok{ a}
       \OtherTok{->} \DataTypeTok{Uncert}\NormalTok{ a}
       \OtherTok{->} \DataTypeTok{Uncert}\NormalTok{ a}
       \OtherTok{->} \DataTypeTok{Uncert}\NormalTok{ a}
\NormalTok{liftU3 f x y z }\FunctionTok{=}\NormalTok{ liftUF (\textbackslash{}(}\DataTypeTok{V3}\NormalTok{ x' y' z') }\OtherTok{->}\NormalTok{ f x' y' z') (}\DataTypeTok{V3}\NormalTok{ x y z)}
\end{Highlighting}
\end{Shaded}

At this point, our code is pretty much complete. We can fill in the other
two-argument functions from the numeric typeclasses:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{(}\FunctionTok{+}\NormalTok{)     }\FunctionTok{=}\NormalTok{ liftU2 (}\FunctionTok{+}\NormalTok{)}
\NormalTok{(}\FunctionTok{*}\NormalTok{)     }\FunctionTok{=}\NormalTok{ liftU2 (}\FunctionTok{*}\NormalTok{)}
\NormalTok{(}\FunctionTok{/}\NormalTok{)     }\FunctionTok{=}\NormalTok{ liftU2 (}\FunctionTok{/}\NormalTok{)}
\NormalTok{(}\FunctionTok{**}\NormalTok{)    }\FunctionTok{=}\NormalTok{ liftU2 (}\FunctionTok{**}\NormalTok{)}
\NormalTok{logBase }\FunctionTok{=}\NormalTok{ liftU2 logBase}
\end{Highlighting}
\end{Shaded}

Admittedly, there's still some slight boilerplate (that you can get rid of with
some Template Haskell, maybe), but you have a \emph{lot} less room for error,
and a lot simpler to check over and read to make sure you didn't miss any bugs.

\hypertarget{wrapping-it-up}{%
\section{Wrapping it up}\label{wrapping-it-up}}

The full code (with all of the numeric instances fully implemented) is up
\href{https://github.com/mstksg/inCode/tree/master/code-samples/uncertain/Uncertain.hs}{on
github}, which you can run and explore and test by executing it or loading it
with \texttt{stack\ ghci}. I've added a special \emph{Show} instance that
``rounds'' your values to as many digits that your uncertainty suggests, to give
more meaningful \texttt{show}s.

All of what's in this post is actually up on my
\emph{\href{https://hackage.haskell.org/package/uncertain}{uncertain}} package
on hackage, if you want to use it in your own projects, or see how I take this
and make it more robust for real-world applications. The project also has more
features on top of the basic things shown here.

\hypertarget{verification-and-accuracy}{%
\subsection{Verification and Accuracy}\label{verification-and-accuracy}}

My \emph{\href{https://hackage.haskell.org/package/uncertain}{uncertain}}
package has a Monte Carlo module to propagate uncertainty through Monte Carlo
simulations. Let's see how the values compare!

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ghci}\FunctionTok{>}\NormalTok{ x }\FunctionTok{+}\NormalTok{ y         }\CommentTok{-- Monte Carlo Results:}
\DecValTok{46} \FunctionTok{+/-} \DecValTok{2}            \CommentTok{-- actually 46 +/- 2}
\NormalTok{ghci}\FunctionTok{>}\NormalTok{ x }\FunctionTok{*}\NormalTok{ y}
\DecValTok{450} \FunctionTok{+/-} \DecValTok{40}          \CommentTok{-- actually 450 +/- 40}
\NormalTok{ghci}\FunctionTok{>}\NormalTok{ sqrt (x }\FunctionTok{+}\NormalTok{ y)}
\FloatTok{6.8} \FunctionTok{+/-} \FloatTok{0.2}         \CommentTok{-- actually 6.8 +/- 0.2}
\NormalTok{ghci}\FunctionTok{>}\NormalTok{ logBase y x}
\FloatTok{0.78} \FunctionTok{+/-} \FloatTok{0.02}       \CommentTok{-- actually 0.78 +/- 0.02}
\NormalTok{ghci}\FunctionTok{>}\NormalTok{ log (x}\FunctionTok{**}\NormalTok{y)}
\FloatTok{85.9} \FunctionTok{+/-} \FloatTok{0.3}        \CommentTok{-- actually 83 +/- 6}
\end{Highlighting}
\end{Shaded}

So, it looks like the mathematical model of uncertainty propagation matched up
well with the ``actual'' results we gain from Monte Carlo simulations! The only
one of our examples that was significantly wrong was the
\includegraphics{https://latex.codecogs.com/png.latex?\%5Coperatorname\%7Blog\%7D\%28x\%5Ey\%29}
example, which heavily underestimated the uncertainty by about a factor of 20.
But, remember, the model was derived after dropping the 2nd, 3rd, 4th, etc.
terms of the taylor expansion for the calculation of the new uncertainty, and
the 4th, 6th, etc. terms of the taylor expansion for the calculation of the new
mean. For functions that have high second, third, fourth derivatives relative to
the mean and the uncertainty, it's going to be a bit off.

\hypertarget{what-next}{%
\subsection{What next?}\label{what-next}}

For an extension on the mathematics behind this method, Dan Piponi has a
\href{http://blog.sigfpe.com/2011/08/computing-errors-with-square-roots-of.html}{great
article} with a lot of good references for further reading on the formal method.

Going off of what we've done here, a simple extension of this would be to
implement the Monte Carlo simulator I mentioned above, which is pretty
straightforward to implement with the
\emph{\href{https://hackage.haskell.org/package/mwc-random}{mwc-random}}
package.

However, the most unsettling thing here that we never deal with is what happens
correlated terms that are combined. All of our math assumed uncorrelated
samples. But what happens if we have expressions that involve additions of
correlated values?

For example:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ghci}\FunctionTok{>} \KeywordTok{let}\NormalTok{ x }\FunctionTok{=} \FloatTok{14.6} \FunctionTok{+/-} \FloatTok{0.8} \KeywordTok{in}\NormalTok{ x }\FunctionTok{+}\NormalTok{ x}
\DecValTok{29} \FunctionTok{+/-} \DecValTok{1}
\NormalTok{ghci}\FunctionTok{>} \KeywordTok{let}\NormalTok{ x }\FunctionTok{=} \FloatTok{14.6} \FunctionTok{+/-} \FloatTok{0.8} \KeywordTok{in} \DecValTok{2}\FunctionTok{*}\NormalTok{x}
\DecValTok{29} \FunctionTok{+/-} \DecValTok{2}
\end{Highlighting}
\end{Shaded}

Unfortunately, \texttt{x\ +\ x} is different than \texttt{2*x}. This is because
\texttt{x} acts like an \emph{independent generator}, so when you say
\texttt{x\ +\ x}, it expands to \texttt{(14.6\ +/-\ 0.8)\ +\ (14.6\ +/-\ 0.8)},
which represents the addition of two independent samples.

When you say \texttt{2*x}, that represents sampling \texttt{x} \emph{once} and
\emph{doubling} it. If you sample \texttt{x} and double it, any error in
\texttt{x} will also be doubled. That's why the uncertainty is greater in the
\texttt{2*x} version.

How can we account for correlated values that are combined in complex ways? Stay
tuned for the next part of the
\href{https://blog.jle.im/entries/series/+uncertain.html}{series}!\footnote{Or
  just look at my \href{https://hackage.haskell.org/package/uncertain}{package}
  :)}

Hi, thanks for reading! You can reach me via email at
\href{mailto:justin@jle.im}{\nolinkurl{justin@jle.im}}, or at twitter at
\href{https://twitter.com/mstk}{@mstk}! This post and all others are published
under the \href{https://creativecommons.org/licenses/by-nc-nd/3.0/}{CC-BY-NC-ND
3.0} license. Corrections and edits via pull request are welcome and encouraged
at \href{https://github.com/mstksg/inCode}{the source repository}.

If you feel inclined, or this post was particularly helpful for you, why not
consider \href{https://www.patreon.com/justinle}{supporting me on Patreon}, or a
\href{bitcoin:3D7rmAYgbDnp4gp4rf22THsGt74fNucPDU}{BTC donation}? :)

\end{document}
